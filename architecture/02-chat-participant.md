### 2. Chat Participant API (@workspace, @copilot, etc.)

#### End-to-End Interaction Flow (vscode-copilot-chat Example)

This diagram shows the complete request lifecycle when a user asks `@workspace explain this function` in VS Code's chat panel.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USER ACTION                                                                  â”‚
â”‚ Types in chat: "@workspace explain how authentication works"                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VS CODE CORE - Chat Widget (Main Thread)                                    â”‚
â”‚ File: src/vs/workbench/contrib/chat/browser/chatWidget.ts                   â”‚
â”‚                                                                              â”‚
â”‚ 1. Parse user input:                                                        â”‚
â”‚    â€¢ Participant: "@workspace"                                              â”‚
â”‚    â€¢ Command: (none)                                                        â”‚
â”‚    â€¢ Prompt: "explain how authentication works"                             â”‚
â”‚    â€¢ Variables: (auto-detected from #references)                            â”‚
â”‚                                                                              â”‚
â”‚ 2. Create ChatRequest object with:                                          â”‚
â”‚    â€¢ prompt: "explain how authentication works"                             â”‚
â”‚    â€¢ location: ChatLocation.Panel                                           â”‚
â”‚    â€¢ model: (user-selected model, e.g., GPT-4)                              â”‚
â”‚    â€¢ references: []                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ chatService.sendRequest()
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VS CODE CORE - ChatService (Main Thread)                                    â”‚
â”‚ File: src/vs/workbench/contrib/chat/common/chatService.ts                   â”‚
â”‚                                                                              â”‚
â”‚ 1. Look up participant by ID: "github.copilot.workspace"                    â”‚
â”‚ 2. Gather conversation history from ChatModel                               â”‚
â”‚ 3. Create ChatContext with history                                          â”‚
â”‚ 4. Validate permissions                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ chatAgentService.invokeAgent()
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VS CODE CORE - ChatAgentService (Main Thread)                               â”‚
â”‚ File: src/vs/workbench/contrib/chat/common/chatAgents.ts                    â”‚
â”‚                                                                              â”‚
â”‚ 1. Find registered participant by ID                                        â”‚
â”‚ 2. Get participant's request handler                                        â”‚
â”‚ 3. Create progress tracker for streaming                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ RPC: Call extension host (IPC boundary)
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EXTENSION HOST - ExtHostChatAgents                                          â”‚
â”‚ File: src/vs/workbench/api/common/extHostChatAgents.ts                      â”‚
â”‚                                                                              â”‚
â”‚ 1. Receive request from main thread                                         â”‚
â”‚ 2. Find handler by participant ID                                           â”‚
â”‚ 3. Create API objects (ChatRequest, ChatResponseStream)                     â”‚
â”‚ 4. Bridge progress callbacks across IPC                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ handler(request, context, stream, token)
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VSCODE-COPILOT-CHAT - ChatAgents.getChatParticipantHandler()                â”‚
â”‚ File: src/extension/conversation/vscode-node/chatParticipants.ts            â”‚
â”‚ Layer 1: Registration & Routing                                             â”‚
â”‚                                                                              â”‚
â”‚ 1. Check privacy confirmation (for 3rd party models)                        â”‚
â”‚    â€¢ If needed, show confirmation UI and return                             â”‚
â”‚                                                                              â”‚
â”‚ 2. Check quota status                                                       â”‚
â”‚    â€¢ If quota exhausted, auto-switch to base model                          â”‚
â”‚    â€¢ Show warning message to user                                           â”‚
â”‚                                                                              â”‚
â”‚ 3. Signal interaction started (telemetry)                                   â”‚
â”‚                                                                              â”‚
â”‚ 4. Resolve intent ID:                                                       â”‚
â”‚    â€¢ Default for @workspace: Intent.Workspace                               â”‚
â”‚    â€¢ Check if slash command specified                                       â”‚
â”‚    â€¢ Map command to intent if present                                       â”‚
â”‚                                                                              â”‚
â”‚ 5. Create ChatParticipantRequestHandler                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ new ChatParticipantRequestHandler()
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VSCODE-COPILOT-CHAT - ChatParticipantRequestHandler.constructor()           â”‚
â”‚ File: src/extension/prompt/node/chatParticipantRequestHandler.ts            â”‚
â”‚ Layer 2: Intent Selection & Context                                         â”‚
â”‚                                                                              â”‚
â”‚ Constructor Phase:                                                           â”‚
â”‚ 1. Parse location (panel, editor, terminal, notebook)                       â”‚
â”‚                                                                              â”‚
â”‚ 2. Reconstruct Conversation from VS Code history:                           â”‚
â”‚    â€¢ Convert ChatRequestTurn[] â†’ Turn[]                                     â”‚
â”‚    â€¢ Restore previous prompts, responses, metadata                          â”‚
â”‚    â€¢ Extract session ID from previous turns                                 â”‚
â”‚                                                                              â”‚
â”‚ 3. Infer document context (for inline chat):                                â”‚
â”‚    â€¢ Active file URI                                                        â”‚
â”‚    â€¢ Current selection range                                                â”‚
â”‚    â€¢ Language ID                                                            â”‚
â”‚                                                                              â”‚
â”‚ 4. Initialize telemetry tracking:                                           â”‚
â”‚    â€¢ Session ID                                                             â”‚
â”‚    â€¢ Message ID                                                             â”‚
â”‚    â€¢ Timing info                                                            â”‚
â”‚                                                                              â”‚
â”‚ 5. Create Turn for this request                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ handler.getResult()
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VSCODE-COPILOT-CHAT - ChatParticipantRequestHandler.getResult()             â”‚
â”‚ Layer 2: Intent Selection & Context (continued)                             â”‚
â”‚                                                                              â”‚
â”‚ 1. Check permissive auth requirement:                                       â”‚
â”‚    â€¢ Using workspace tool (@workspace or codebase tool)?                    â”‚
â”‚    â€¢ User has full repo access?                                             â”‚
â”‚    â€¢ If not, show auth upgrade confirmation                                 â”‚
â”‚                                                                              â”‚
â”‚ 2. Sanitize variables:                                                      â”‚
â”‚    â€¢ Check each reference against .copilotignore                            â”‚
â”‚    â€¢ Check against .gitignore                                               â”‚
â”‚    â€¢ Remove ignored files from references                                   â”‚
â”‚    â€¢ Also sanitize user message (remove file paths)                         â”‚
â”‚                                                                              â”‚
â”‚ 3. Get command details:                                                     â”‚
â”‚    â€¢ Look up command by intentId                                            â”‚
â”‚    â€¢ Validate command usage (check if args required)                        â”‚
â”‚                                                                              â”‚
â”‚ 4. Select Intent:                                                           â”‚
â”‚    â€¢ If command specified â†’ use command.intent                              â”‚
â”‚    â€¢ If inline chat (editor) â†’ use heuristics:                              â”‚
â”‚      - Empty line + cursor â†’ Intent.Generate                                â”‚
â”‚      - Multi-line selection â†’ Intent.Edit                                   â”‚
â”‚    â€¢ Else â†’ Intent.Unknown (will detect from prompt)                        â”‚
â”‚                                                                              â”‚
â”‚ 5. Check if intent has custom handler:                                      â”‚
â”‚    â€¢ intent.handleRequest() exists? â†’ Call it directly                      â”‚
â”‚    â€¢ Else â†’ Create DefaultIntentRequestHandler                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ new DefaultIntentRequestHandler()
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VSCODE-COPILOT-CHAT - DefaultIntentRequestHandler.constructor()             â”‚
â”‚ File: src/extension/prompt/node/defaultIntentRequestHandler.ts              â”‚
â”‚ Layer 3: Intent Execution                                                   â”‚
â”‚                                                                              â”‚
â”‚ Constructor:                                                                 â”‚
â”‚ â€¢ Store intent, conversation, request, stream, token                        â”‚
â”‚ â€¢ Store document context, location, telemetry builder                       â”‚
â”‚ â€¢ Get latest Turn from conversation                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ handler.getResult()
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VSCODE-COPILOT-CHAT - DefaultIntentRequestHandler.getResult()               â”‚
â”‚ Layer 3: Intent Execution (continued)                                       â”‚
â”‚                                                                              â”‚
â”‚ 1. Check for tool call limit cancellation                                   â”‚
â”‚                                                                              â”‚
â”‚ 2. Invoke Intent:                                                           â”‚
â”‚    intent.invoke({ location, documentContext, request })                    â”‚
â”‚    â†’ Returns IIntentInvocation with:                                        â”‚
â”‚       â€¢ buildPrompt() function                                              â”‚
â”‚       â€¢ getAvailableTools() function                                        â”‚
â”‚       â€¢ endpoint configuration                                              â”‚
â”‚       â€¢ response processing config                                          â”‚
â”‚                                                                              â”‚
â”‚ 3. Store intent invocation metadata in turn                                 â”‚
â”‚                                                                              â”‚
â”‚ 4. Handle confirmations (if needed for destructive actions)                 â”‚
â”‚                                                                              â”‚
â”‚ 5. Run tool calling loop:                                                   â”‚
â”‚    â†’ Delegates to DefaultToolCallingLoop                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ runWithToolCalling()
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VSCODE-COPILOT-CHAT - DefaultToolCallingLoop                                â”‚
â”‚ Layer 3: Agent Execution Loop                                               â”‚
â”‚                                                                              â”‚
â”‚ Initialization:                                                              â”‚
â”‚ â€¢ Create response stream participants (linkify, telemetry, etc.)            â”‚
â”‚ â€¢ Wire up event handlers (onDidBuildPrompt, onDidReceiveResponse)           â”‚
â”‚ â€¢ Create pause controller                                                   â”‚
â”‚                                                                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚ â”‚ LOOP: Until done or max iterations (15)                      â”‚            â”‚
â”‚ â”‚                                                               â”‚            â”‚
â”‚ â”‚ Iteration N:                                                  â”‚            â”‚
â”‚ â”‚                                                               â”‚            â”‚
â”‚ â”‚ 1. BUILD PROMPT                                               â”‚            â”‚
â”‚ â”‚    â€¢ Call intentInvocation.buildPrompt()                     â”‚            â”‚
â”‚ â”‚    â€¢ Uses @vscode/prompt-tsx to render:                      â”‚            â”‚
â”‚ â”‚      - System message (intent-specific)                      â”‚            â”‚
â”‚ â”‚      - Conversation history                                  â”‚            â”‚
â”‚ â”‚      - Context (files, diagnostics, symbols)                 â”‚            â”‚
â”‚ â”‚      - Tool definitions (file_search, read_file, etc.)       â”‚            â”‚
â”‚ â”‚      - User message                                          â”‚            â”‚
â”‚ â”‚    â€¢ Count tokens, respect context window limits             â”‚            â”‚
â”‚ â”‚    â€¢ Fire onDidBuildPrompt event                             â”‚            â”‚
â”‚ â”‚                                                               â”‚            â”‚
â”‚ â”‚ 2. SEND TO LANGUAGE MODEL                                     â”‚            â”‚
â”‚ â”‚    â€¢ Get endpoint (Azure/GitHub/Anthropic)                   â”‚            â”‚
â”‚ â”‚    â€¢ Authenticate                                            â”‚            â”‚
â”‚ â”‚    â€¢ POST request with streaming                             â”‚            â”‚
â”‚ â”‚                                                               â”‚            â”‚
â”‚ â”‚ 3. PROCESS STREAMING RESPONSE                                 â”‚            â”‚
â”‚ â”‚    â€¢ Parse SSE (Server-Sent Events)                          â”‚            â”‚
â”‚ â”‚    â€¢ Extract chunks:                                         â”‚            â”‚
â”‚ â”‚      - Text: stream.markdown()                               â”‚            â”‚
â”‚ â”‚      - Tool calls: extract name, arguments                   â”‚            â”‚
â”‚ â”‚      - Citations: stream.reference()                         â”‚            â”‚
â”‚ â”‚    â€¢ Apply response stream participants:                     â”‚            â”‚
â”‚ â”‚      - Linkification (convert URLs/paths to links)           â”‚            â”‚
â”‚ â”‚      - Code block tracking                                   â”‚            â”‚
â”‚ â”‚      - Edit survival tracking (inline chat)                  â”‚            â”‚
â”‚ â”‚      - Telemetry collection                                  â”‚            â”‚
â”‚ â”‚    â€¢ Fire onDidReceiveResponse event                         â”‚            â”‚
â”‚ â”‚                                                               â”‚            â”‚
â”‚ â”‚ 4. EXECUTE TOOLS (if any tool calls)                         â”‚            â”‚
â”‚ â”‚    For each tool call:                                       â”‚            â”‚
â”‚ â”‚    â€¢ stream.prepareToolInvocation(toolName)                  â”‚            â”‚
â”‚ â”‚    â€¢ Execute tool:                                           â”‚            â”‚
â”‚ â”‚      - file_search: Search codebase                          â”‚            â”‚
â”‚ â”‚      - read_file: Read file contents                         â”‚            â”‚
â”‚ â”‚      - run_command: Execute shell command                    â”‚            â”‚
â”‚ â”‚      - etc.                                                  â”‚            â”‚
â”‚ â”‚    â€¢ Collect results                                         â”‚            â”‚
â”‚ â”‚    â€¢ Add results to conversation as ToolResultMessage        â”‚            â”‚
â”‚ â”‚                                                               â”‚            â”‚
â”‚ â”‚ 5. CHECK TERMINATION                                          â”‚            â”‚
â”‚ â”‚    Stop if:                                                  â”‚            â”‚
â”‚ â”‚    â€¢ No tool calls in response (final answer)                â”‚            â”‚
â”‚ â”‚    â€¢ Hit max iterations (15)                                 â”‚            â”‚
â”‚ â”‚    â€¢ User cancelled (token.isCancellationRequested)          â”‚            â”‚
â”‚ â”‚    â€¢ User paused interaction                                 â”‚            â”‚
â”‚ â”‚                                                               â”‚            â”‚
â”‚ â”‚    Continue if:                                              â”‚            â”‚
â”‚ â”‚    â€¢ Model made tool calls â†’ Loop with results               â”‚            â”‚
â”‚ â”‚                                                               â”‚            â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                              â”‚
â”‚ After Loop Completes:                                                        â”‚
â”‚ â€¢ Collect all tool call rounds                                              â”‚
â”‚ â€¢ Send tool calling telemetry                                               â”‚
â”‚ â€¢ Return result with metadata                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ Return to DefaultIntentRequestHandler
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VSCODE-COPILOT-CHAT - DefaultIntentRequestHandler.getResult()               â”‚
â”‚                                                                              â”‚
â”‚ 6. Process Result:                                                          â”‚
â”‚    â€¢ Check response type (success, error, filtered, quota, etc.)            â”‚
â”‚    â€¢ Handle each case:                                                      â”‚
â”‚      - Success: Set turn status, send telemetry                             â”‚
â”‚      - OffTopic: Show rejection message                                     â”‚
â”‚      - QuotaExceeded: Show quota error with upgrade link                    â”‚
â”‚      - RateLimited: Show rate limit error with retry time                   â”‚
â”‚      - Filtered: Content filter triggered                                   â”‚
â”‚      - NetworkError: Connection issue                                       â”‚
â”‚      - etc.                                                                 â”‚
â”‚                                                                              â”‚
â”‚ 7. Update Turn:                                                             â”‚
â”‚    â€¢ Set response text                                                      â”‚
â”‚    â€¢ Set status (Success, Error, Cancelled, etc.)                           â”‚
â”‚    â€¢ Attach metadata (tool calls, token counts, etc.)                       â”‚
â”‚                                                                              â”‚
â”‚ 8. Show warnings:                                                           â”‚
â”‚    â€¢ If files were ignored: show message                                    â”‚
â”‚                                                                              â”‚
â”‚ 9. Return ChatResult                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ Return to ChatParticipantRequestHandler
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VSCODE-COPILOT-CHAT - ChatParticipantRequestHandler.getResult()             â”‚
â”‚                                                                              â”‚
â”‚ 6. Add endpoint information:                                                â”‚
â”‚    â€¢ result.details = "Claude 3.5 Sonnet â€¢ 3x"                              â”‚
â”‚                                                                              â”‚
â”‚ 7. Store conversation:                                                      â”‚
â”‚    â€¢ conversationStore.addConversation(turnId, conversation)                â”‚
â”‚    â€¢ Allows retrieval in future requests                                    â”‚
â”‚                                                                              â”‚
â”‚ 8. Add metadata:                                                            â”‚
â”‚    â€¢ modelMessageId                                                         â”‚
â”‚    â€¢ responseId                                                             â”‚
â”‚    â€¢ sessionId                                                              â”‚
â”‚    â€¢ agentId: "github.copilot.workspace"                                    â”‚
â”‚    â€¢ command: undefined                                                     â”‚
â”‚                                                                              â”‚
â”‚ 9. Return ICopilotChatResult                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ Return to getChatParticipantHandler()
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VSCODE-COPILOT-CHAT - ChatAgents.getChatParticipantHandler()                â”‚
â”‚                                                                              â”‚
â”‚ Return vscode.ChatResult to VS Code                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ RPC: Return to main thread (IPC boundary)
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EXTENSION HOST - ExtHostChatAgents                                          â”‚
â”‚                                                                              â”‚
â”‚ â€¢ Convert ChatResult to wire format                                         â”‚
â”‚ â€¢ Send back to main thread                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VS CODE CORE - ChatAgentService                                             â”‚
â”‚                                                                              â”‚
â”‚ â€¢ Receive result from extension host                                        â”‚
â”‚ â€¢ Update ChatModel with response                                            â”‚
â”‚ â€¢ Store in conversation history                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VS CODE CORE - ChatService                                                  â”‚
â”‚                                                                              â”‚
â”‚ â€¢ Update session state                                                      â”‚
â”‚ â€¢ Fire events (onDidPerformUserAction, etc.)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VS CODE CORE - Chat Widget                                                  â”‚
â”‚                                                                              â”‚
â”‚ â€¢ Render final response in UI                                               â”‚
â”‚ â€¢ Show follow-up suggestions                                                â”‚
â”‚ â€¢ Enable thumbs up/down feedback                                            â”‚
â”‚ â€¢ Show "Regenerate" button                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USER SEES RESPONSE                                                           â”‚
â”‚                                                                              â”‚
â”‚ Chat Panel shows:                                                            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚ â”‚ @workspace                                              â­ ğŸ‘             â”‚
â”‚ â”‚                                                                            â”‚
â”‚ â”‚ The authentication system in this codebase uses JWT     â”‚              â”‚
â”‚ â”‚ tokens with OAuth 2.0. Here's how it works:             â”‚              â”‚
â”‚ â”‚                                                          â”‚              â”‚
â”‚ â”‚ [View auth.ts] [View middleware.ts]                     â”‚              â”‚
â”‚ â”‚                                                          â”‚              â”‚
â”‚ â”‚ Used tools:                                             â”‚              â”‚
â”‚ â”‚ â€¢ file_search - Searched for authentication files       â”‚              â”‚
â”‚ â”‚ â€¢ read_file - Read auth.ts, middleware.ts              â”‚              â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                              â”‚
â”‚ Follow-up suggestions:                                                       â”‚
â”‚ â€¢ "Show me how to add a new authentication method"                          â”‚
â”‚ â€¢ "Explain the token refresh mechanism"                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Observations:**

1. **IPC Boundaries**: Request crosses from main thread â†’ extension host â†’ back to main thread multiple times for streaming

2. **Three-Layer Processing in Extension**:
   - Layer 1 (ChatAgents): Routing, quota, privacy
   - Layer 2 (ChatParticipantRequestHandler): Intent selection, context, sanitization
   - Layer 3 (DefaultIntentRequestHandler): Intent execution, tool calling, response processing

3. **Streaming**: Every `stream.markdown()` call flows back through all layers immediately - user sees real-time updates

4. **Tool Calling Loop**: Can iterate up to 15 times, each time:
   - Builds new prompt with tool results
   - Calls LLM again
   - Processes new response
   - Executes any new tool calls

5. **Context Window Management**: Prompt builder respects token limits, truncates conversation history if needed

6. **Error Handling**: 24+ error types handled at various layers with user-friendly messages

7. **Telemetry**: Tracked at every layer for product insights and A/B testing

8. **Conversation Persistence**: Full conversation stored and reconstructed on every request (VS Code doesn't maintain it)

---

#### Overview

The Chat Participant API allows extensions to create specialized AI assistants that appear in VS Code's native chat interface. When users type `@participantName`, your custom handler processes the request.

**Purpose:**
Chat participants are the primary way to create conversational AI features in VS Code. Unlike the Language Model Provider API (which provides the AI models), chat participants use those models to implement specific workflows and capabilities.

**Key Differences from Language Model Provider API:**

| Language Model Provider API | Chat Participant API |
|---------------------------|---------------------|
| Provides AI models | Uses AI models |
| Low-level: handles API calls | High-level: implements features |
| Example: GitHub Copilot extension | Example: @workspace, @terminal, @vscode |
| One per model vendor | Many per extension |
| Registered via `vscode.lm.registerChatModelProvider()` | Registered via `vscode.chat.createChatParticipant()` |

**Built-in Participants in VS Code:**
- `@workspace`: Answers questions about your codebase
- `@vscode`: Helps with VS Code features and settings
- `@terminal`: Assists with shell commands

**Use Cases:**

1. **Domain-Specific Assistants**: 
   - `@database`: SQL query helper
   - `@api`: REST API design assistant
   - `@security`: Code security scanner

2. **Workflow Automation**:
   - `@test`: Generates and runs tests
   - `@docs`: Creates documentation
   - `@refactor`: Code improvement suggestions

3. **Tool Integration**:
   - `@jira`: Manages issues
   - `@github`: PR reviews and repo management
   - `@docker`: Container management

4. **Learning & Education**:
   - `@tutor`: Interactive coding lessons
   - `@explain`: Detailed code explanations

**How It Works:**
1. User types `@yourParticipant explain this function` in chat
2. VS Code parses the message and routes to your handler
3. Your handler receives the request with context (selected code, workspace info, etc.)
4. You use `request.model.sendRequest()` to call any available language model
5. Stream responses back via the `ChatResponseStream` interface
6. VS Code renders the response with markdown, code blocks, buttons, etc.

#### Key Interfaces

**vscode.proposed.chatParticipantAdditions.d.ts:**

These interfaces define how chat participants interact with VS Code's chat system.

```typescript
/**
 * Represents a user's chat request to a participant.
 * Contains the prompt, selected model, context, and metadata.
 */
export interface ChatRequest {
    /**
     * Slash command used (e.g., /fix, /explain, /tests).
     * undefined if no command was specified.
     */
    readonly command: string | undefined;
    
    /**
     * The user's message after removing participant name and command.
     * Example: If user types "@workspace /explain how auth works"
     *          prompt = "how auth works"
     */
    readonly prompt: string;
    
    /**
     * Files, symbols, or URIs that user explicitly referenced with #.
     * Example: "@workspace explain #file:auth.ts #symbol:login"
     */
    readonly references: readonly ChatPromptReference[];
    
    /**
     * Where the chat was invoked: 'panel' (chat view) or 'editor' (inline)
     */
    readonly location: ChatLocation;
    
    /**
     * Retry count if user clicked "regenerate response" (starts at 0)
     */
    readonly attempt: number;
    
    /**
     * If true, VS Code will detect /commands automatically in the prompt
     */
    readonly enableCommandDetection: boolean;
    
    /**
     * The language model selected by the user (e.g., GPT-4, Claude 3.5).
     * Use model.sendRequest() to interact with this model.
     */
    readonly model: LanguageModelChat;
    
    // Private additions (chatParticipantPrivate) - not in stable API
    readonly id: string;              // Unique request ID
    readonly sessionId: string;       // Chat session ID (persists across requests)
    readonly locationData?: ChatLocationData;  // Detailed editor context
}

/**
 * Represents a registered chat participant.
 * Return this from vscode.chat.createChatParticipant() and configure its properties.
 */
export interface ChatParticipant {
    /**
     * Icon shown next to participant name in chat UI.
     * Can be a file URI, theme icon (e.g., $(robot)), or light/dark variants.
     */
    iconPath?: Uri | { light: Uri; dark: Uri } | ThemeIcon;
    
    /**
     * Your main handler function - called when user sends a message to your participant.
     * This is where all the logic lives.
     */
    requestHandler: ChatRequestHandler;
    
    /**
     * Optional: Provide follow-up questions after each response.
     * Example: After explaining code, suggest "Would you like to see tests for this?"
     */
    followupProvider?: ChatFollowupProvider;
    
    /**
     * Event fired when user clicks thumbs up/down on your response.
     * Use for analytics and model improvement.
     */
    onDidReceiveFeedback: Event<ChatResultFeedback>;
}

/**
 * Your main request handler function.
 * This is called whenever a user sends a message to your participant.
 * 
 * @param request - The user's request with prompt, references, model selection
 * @param context - Conversation history and previous responses
 * @param response - Stream interface to send responses back to UI
 * @param token - Cancellation token (user can cancel long requests)
 * @returns Optional ChatResult with metadata (error info, model used, etc.)
 */
export type ChatRequestHandler = (
    request: ChatRequest,
    context: ChatContext,
    response: ChatResponseStream,
    token: CancellationToken
) => ProviderResult<ChatResult>;

/**
 * Interface for streaming responses back to the chat UI.
 * All methods update the UI immediately - users see responses in real-time.
 */
export interface ChatResponseStream {
    /**
     * Append markdown content to the response.
     * Supports full markdown syntax: bold, italic, code blocks, lists, tables, etc.
     * 
     * Example:
     *   stream.markdown('Here is the **solution**:\n```typescript\nconst x = 42;\n```');
     */
    markdown(value: string | MarkdownString): void;
    
    /**
     * Add a clickable link to a file or location.
     * Clicking opens the file/location in the editor.
     * 
     * Example:
     *   stream.anchor(vscode.Uri.file('/path/to/file.ts'), 'View implementation');
     */
    anchor(value: Uri | Location, title?: string): void;
    
    /**
     * Add an interactive button that executes a command when clicked.
     * 
     * Example:
     *   stream.button({
     *     title: 'Run Tests',
     *     command: 'workbench.action.tasks.runTask',
     *     arguments: ['npm test']
     *   });
     */
    button(command: Command): void;
    
    /**
     * Show a progress message above the response.
     * Useful for long-running operations: "Analyzing codebase...", "Running tests..."
     * 
     * Example:
     *   stream.progress('Searching workspace for similar code...');
     */
    progress(value: string): void;
    
    /**
     * Add a reference to a file or symbol that was used to generate the response.
     * Appears as a collapsible "References" section.
     * 
     * Example:
     *   stream.reference(vscode.Uri.file('/src/auth.ts'));
     */
    reference(value: Uri | Location): void;
    
    /**
     * Low-level method to push any ChatResponsePart.
     * Prefer specific methods above for better type safety.
     */
    push(part: ChatResponsePart): void;
    
    // Advanced features (chatParticipantAdditions)
    
    /**
     * Indicate that you're about to invoke a tool/function.
     * Shows "Using tool: <toolName>" in the UI.
     */
    prepareToolInvocation(toolName: string): void;
    
    /**
     * Attribute code snippets to their source (for AI-generated code).
     * Shows license info and original source.
     */
    codeCitation(value: Uri, license: string, snippet: string): void;
}

export namespace chat {
    export function createChatParticipant(
        id: string,
        handler: ChatRequestHandler
    ): ChatParticipant;
}
```

#### Real-World Implementation (from vscode-copilot-chat)

**Important**: GitHub Copilot does NOT use a simple handler function like the basic samples. Instead, it implements a **sophisticated three-layer architecture** with clear separation of concerns:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: ChatAgents - Participant Registration & Routing     â”‚
â”‚  File: src/extension/conversation/vscode-node/chatParticipants.ts
â”‚  â€¢ Registers all participants (@copilot, @workspace, etc.)    â”‚
â”‚  â€¢ Routes requests to ChatParticipantRequestHandler           â”‚
â”‚  â€¢ Manages participant lifecycle and configuration            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ Creates handler for each request
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: ChatParticipantRequestHandler - Intent Selection    â”‚
â”‚  File: src/extension/prompt/node/chatParticipantRequestHandler.ts
â”‚  â€¢ Detects user intent (explain, fix, generate, etc.)         â”‚
â”‚  â€¢ Manages conversation history & context                     â”‚
â”‚  â€¢ Handles variable sanitization (respects .gitignore)        â”‚
â”‚  â€¢ Creates Intent objects and invokes them                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ Delegates to intent-specific handler
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: DefaultIntentRequestHandler - Intent Execution      â”‚
â”‚  File: src/extension/prompt/node/defaultIntentRequestHandler.ts
â”‚  â€¢ Invokes specific intent (IIntent.invoke())                 â”‚
â”‚  â€¢ Builds prompt with context via @vscode/prompt-tsx          â”‚
â”‚  â€¢ Manages tool calling loops (agent mode)                    â”‚
â”‚  â€¢ Processes streaming responses                              â”‚
â”‚  â€¢ Handles errors and telemetry                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why This Architecture?**

GitHub Copilot handles complex scenarios that simple handlers can't:
1. **Multiple Participants**: @copilot, @workspace, @vscode, @terminal, @github
2. **Intent Detection**: Automatically detect if user wants to explain, fix, generate, or refactor code
3. **Tool Calling (Agent Mode)**: Multi-step reasoning with function calling (read files, run commands, etc.)
4. **Context Management**: Smart context gathering from workspace, editor selections, diagnostics
5. **Prompt Engineering**: Complex prompt construction with conversation history, system messages, and tool definitions
6. **Error Handling**: Graceful handling of rate limits, quota exhaustion, content filtering

---

#### Layer 1: ChatAgents - Participant Registration

**File: `src/extension/conversation/vscode-node/chatParticipants.ts`**

This class orchestrates the registration of all chat participants and routes requests to the appropriate handler.

**Responsibilities:**
- Creates and configures multiple participants (@copilot, @workspace, @vscode, etc.)
- Sets participant properties (icon, description, welcome message, etc.)
- Provides the bridge between VS Code's participant API and Copilot's intent system
- Handles authentication state changes and quota management

**Key Patterns:**
1. **Dependency Injection**: Uses `IInstantiationService` to create handlers with proper services
2. **Agent Factory**: `createAgent()` method encapsulates common participant creation logic
3. **Intent Mapping**: Maps each participant to a default intent (Intent.Unknown, Intent.Workspace, etc.)
4. **Dynamic Configuration**: Adjusts participant behavior based on user auth state and quota

```typescript
/**
 * Service that manages registration of all chat participants.
 * Instantiated once per extension activation.
 */
export class ChatAgentService implements IChatAgentService {
    private _lastChatAgents: ChatAgents | undefined;

    constructor(
        @IInstantiationService private readonly instantiationService: IInstantiationService,
    ) { }

    /**
     * Register all participants and return a disposable to clean up.
     * Called from extension activation.
     */
    register(): IDisposable {
        const chatAgents = this.instantiationService.createInstance(ChatAgents);
        chatAgents.register();
        this._lastChatAgents = chatAgents;
        return {
            dispose: () => {
                chatAgents.dispose();
                this._lastChatAgents = undefined;
            }
        };
    }
}

/**
 * Internal class that registers all the individual participants.
 */
class ChatAgents implements IDisposable {
    private readonly _disposables = new DisposableStore();

    constructor(
        @IOctoKitService private readonly octoKitService: IOctoKitService,
        @IAuthenticationService private readonly authenticationService: IAuthenticationService,
        @IInstantiationService private readonly instantiationService: IInstantiationService,
        @IUserFeedbackService private readonly userFeedbackService: IUserFeedbackService,
        @IEndpointProvider private readonly endpointProvider: IEndpointProvider,
        @IFeedbackReporter private readonly feedbackReporter: IFeedbackReporter,
        @IInteractionService private readonly interactionService: IInteractionService,
        @IChatQuotaService private readonly _chatQuotaService: IChatQuotaService,
        @IConfigurationService private readonly configurationService: IConfigurationService,
    ) { }

    dispose() {
        this._disposables.dispose();
    }

    /**
     * Register all chat participants.
     * Each participant gets its own icon, intent, and configuration.
     */
    register(): void {
        this.additionalWelcomeMessage = this.instantiationService.invokeFunction(getAdditionalWelcomeMessage);
        this._disposables.add(this.registerDefaultAgent());        // @copilot
        this._disposables.add(this.registerEditingAgent());        // Inline chat
        this._disposables.add(this.registerEditingAgent2());       // Agent mode
        this._disposables.add(this.registerEditingAgentEditor()); // Editor inline
        this._disposables.add(this.registerEditsAgent());          // @edits
        this._disposables.add(this.registerEditorDefaultAgent()); // Editor context
        this._disposables.add(this.registerNotebookEditorDefaultAgent()); // Notebook
        this._disposables.add(this.registerNotebookDefaultAgent());
        this._disposables.add(this.registerWorkspaceAgent());      // @workspace
        this._disposables.add(this.registerVSCodeAgent());         // @vscode
        this._disposables.add(this.registerTerminalAgent());       // @terminal
        this._disposables.add(this.registerTerminalPanelAgent());
    }

    /**
     * Factory method to create a participant with common configuration.
     * 
     * @param name - Participant name (e.g., 'copilot', 'workspace')
     * @param defaultIntentIdOrGetter - Intent to use when no command is specified
     * @param options - Additional configuration (custom ID, etc.)
     */
    private createAgent(
        name: string, 
        defaultIntentIdOrGetter: IntentOrGetter, 
        options?: { id?: string }
    ): vscode.ChatParticipant {
        const id = options?.id || getChatParticipantIdFromName(name);
        const onRequestPaused = new Relay<vscode.ChatParticipantPauseStateEvent>();
        
        // Create participant with handler
        const agent = vscode.chat.createChatParticipant(
            id, 
            this.getChatParticipantHandler(id, name, defaultIntentIdOrGetter, onRequestPaused.event)
        );
        
        // Wire up feedback events
        agent.onDidReceiveFeedback(e => {
            this.userFeedbackService.handleFeedback(e, id);
        });
        agent.onDidPerformAction(e => {
            this.userFeedbackService.handleUserAction(e, id);
        });
        
        // Support pause/resume
        if (agent.onDidChangePauseState) {
            onRequestPaused.input = agent.onDidChangePauseState;
        }
        
        return agent;
    }

    /**
     * Register the default @copilot participant.
     * This is the main conversational AI assistant.
     */
    private registerDefaultAgent(): IDisposable {
        // Dynamic intent selection based on experiment
        const intentGetter = (request: vscode.ChatRequest) => {
            if (this.configurationService.getExperimentBasedConfig(
                ConfigKey.TeamInternal.AskAgent, 
                this.experimentationService
            ) && request.model.capabilities.supportsToolCalling) {
                return Intent.AskAgent; // Use agent mode with tool calling
            }
            return Intent.Unknown; // Use standard chat mode
        };
        
        const defaultAgent = this.createAgent(defaultAgentName, intentGetter);
        defaultAgent.iconPath = new vscode.ThemeIcon('copilot');
        
        // Set up GitHub avatar as requester icon
        this.initDefaultAgentRequestorProps(defaultAgent);
        
        // Configure help text
        defaultAgent.helpTextPrefix = vscode.l10n.t(
            'You can ask me general programming questions, or chat with the following participants...'
        );
        
        // Add welcome message, title provider, and summarizer
        defaultAgent.additionalWelcomeMessage = this.additionalWelcomeMessage;
        defaultAgent.titleProvider = this.instantiationService.createInstance(ChatTitleProvider);
        defaultAgent.summarizer = this.instantiationService.createInstance(ChatSummarizerProvider);
        
        return defaultAgent;
    }

    /**
     * Register @workspace participant for codebase questions.
     */
    private registerWorkspaceAgent(): IDisposable {
        const workspaceAgent = this.createAgent(workspaceAgentName, Intent.Workspace);
        workspaceAgent.iconPath = new vscode.ThemeIcon('code');
        return workspaceAgent;
    }

    /**
     * Register @vscode participant for editor help.
     */
    private registerVSCodeAgent(): IDisposable {
        const useInsidersIcon = vscode.env.appName.includes('Insiders');
        const vscodeAgent = this.createAgent(vscodeAgentName, Intent.VSCode);
        vscodeAgent.iconPath = useInsidersIcon 
            ? new vscode.ThemeIcon('vscode-insiders') 
            : new vscode.ThemeIcon('vscode');
        return vscodeAgent;
    }

    /**
     * Register @terminal participant for shell assistance.
     */
    private registerTerminalAgent(): IDisposable {
        const terminalAgent = this.createAgent(terminalAgentName, Intent.Terminal);
        terminalAgent.iconPath = new vscode.ThemeIcon('terminal');
        return terminalAgent;
    }

    /**
     * Creates the actual handler function for a participant.
     * This is called by VS Code every time a user sends a message.
     * 
     * Returns a function that:
     * 1. Handles privacy confirmations (for 3rd party models)
     * 2. Manages quota exhaustion (auto-switch to base model)
     * 3. Creates ChatParticipantRequestHandler for intent detection
     * 4. Returns the result
     */
    private getChatParticipantHandler(
        id: string, 
        name: string, 
        defaultIntentIdOrGetter: IntentOrGetter,
        onRequestPaused: Event<vscode.ChatParticipantPauseStateEvent>
    ): vscode.ChatExtendedRequestHandler {
        return async (request, context, stream, token): Promise<vscode.ChatResult> => {
            
            // Step 1: Privacy confirmation for 3rd party models
            const privacyConfirmation = await this.requestPolicyConfirmation(request, stream);
            if (typeof privacyConfirmation === 'boolean') {
                return {}; // User needs to accept terms first
            }
            request = privacyConfirmation;
            
            // Step 2: Auto-switch to base model if quota exhausted
            request = await this.switchToBaseModel(request, stream);
            
            // Step 3: Signal interaction started (for telemetry)
            this.interactionService.startInteraction();
            
            // Step 4: Resolve intent ID
            const defaultIntentId = typeof defaultIntentIdOrGetter === 'function' ?
                defaultIntentIdOrGetter(request) :
                defaultIntentIdOrGetter;
            
            // Step 5: Map slash command to intent if present
            const commandsForAgent = agentsToCommands[defaultIntentId];
            const intentId = request.command && commandsForAgent ?
                commandsForAgent[request.command] :
                defaultIntentId;
            
            // Step 6: Create handler and process request
            const onPause = Event.chain(onRequestPaused, $ => 
                $.filter(e => e.request === request).map(e => e.isPaused)
            );
            
            const handler = this.instantiationService.createInstance(
                ChatParticipantRequestHandler, 
                context.history, 
                request, 
                stream, 
                token, 
                { agentName: name, agentId: id, intentId }, 
                onPause
            );
            
            return await handler.getResult();
        };
    }
    
    /**
     * Handle privacy confirmation for 3rd party models.
     * If endpoint.policy is not 'enabled', show confirmation UI.
     */
    private async requestPolicyConfirmation(
        request: vscode.ChatRequest, 
        stream: vscode.ChatResponseStream
    ): Promise<boolean | ChatRequest> {
        const endpoint = await this.endpointProvider.getChatEndpoint(request);
        if (endpoint.policy === 'enabled') {
            return request; // No confirmation needed
        }
        
        // Check if user already accepted
        if (request.acceptedConfirmationData?.[0]?.prompt && 
            (await endpoint.acceptChatPolicy())) {
            return { ...request, prompt: request.acceptedConfirmationData[0].prompt };
        }
        
        // Show confirmation UI
        stream.confirmation(
            `Enable ${endpoint.name} for all clients`, 
            endpoint.policy.terms, 
            { prompt: request.prompt }, 
            ['Enable']
        );
        return true; // Signal that confirmation was shown
    }
    
    /**
     * Auto-switch to base model if user exhausted premium quota.
     * Shows warning message explaining the switch.
     */
    private async switchToBaseModel(
        request: vscode.ChatRequest, 
        stream: vscode.ChatResponseStream
    ): Promise<ChatRequest> {
        const endpoint = await this.endpointProvider.getChatEndpoint(request);
        const baseEndpoint = await this.endpointProvider.getChatEndpoint('copilot-base');
        
        // Don't switch if: free model, BYOK, overages enabled, or quota not exhausted
        if (endpoint.multiplier === 0 || 
            request.model.vendor !== 'copilot' || 
            this._chatQuotaService.overagesEnabled || 
            !this._chatQuotaService.quotaExhausted) {
            return request;
        }
        
        // Get base model
        const baseLmModel = (await vscode.lm.selectChatModels({ 
            id: baseEndpoint.model, 
            family: baseEndpoint.family, 
            vendor: 'copilot' 
        }))[0];
        
        if (!baseLmModel) {
            return request;
        }
        
        // Switch model in UI
        await vscode.commands.executeCommand('workbench.action.chat.changeModel', { 
            vendor: baseLmModel.vendor, 
            id: baseLmModel.id, 
            family: baseLmModel.family 
        });
        
        // Show warning
        stream.warning(new vscode.MarkdownString(
            `You have exceeded your premium request allowance. ` +
            `We have automatically switched you to ${baseEndpoint.name}...`
        ));
        
        return { ...request, model: baseLmModel };
    }
}

type IntentOrGetter = Intent | ((request: vscode.ChatRequest) => Intent);
```

**Key Takeaways:**
1. âœ… **Service-Oriented Architecture**: Heavy use of dependency injection for testability
2. âœ… **Quota Management**: Graceful handling of rate limits and premium model exhaustion
3. âœ… **Privacy Controls**: Built-in confirmation flows for 3rd party model policies
4. âœ… **Dynamic Behavior**: Participants adjust based on auth state, experiments, and quotas
5. âœ… **Separation of Concerns**: Registration logic separate from request handling

---

#### Layer 2: ChatParticipantRequestHandler - Intent Selection

**File: `src/extension/prompt/node/chatParticipantRequestHandler.ts`**

This class is the bridge between the VS Code chat participant API and Copilot's intent-based architecture. It's created for **every single chat request** and handles:

**Core Responsibilities:**
1. **Intent Detection & Selection**: Determines what the user wants to do (explain, fix, generate code, etc.)
2. **Conversation Management**: Reconstructs conversation history from VS Code's chat context
3. **Context Gathering**: Collects document context (file, selection, language) for inline chat
4. **Variable Sanitization**: Filters out files that are in `.copilotignore` or `.gitignore`
5. **Permission Handling**: Manages permissive auth upgrades for workspace tools
6. **Error Handling**: Provides user-friendly error messages for empty commands, etc.

**Request Flow:**
```
VS Code Chat API (request arrives)
    â†“
ChatParticipantRequestHandler.constructor()
    â€¢ Parse request location (panel, editor, terminal)
    â€¢ Reconstruct conversation from history
    â€¢ Infer document context from editor state
    â€¢ Initialize telemetry tracking
    â†“
ChatParticipantRequestHandler.getResult()
    â€¢ Sanitize variables (respect .copilotignore)
    â€¢ Check if permissive auth needed
    â€¢ Select appropriate intent
    â€¢ Create DefaultIntentRequestHandler
    â†“
DefaultIntentRequestHandler.getResult()
    â€¢ Invoke intent
    â€¢ Build prompt
    â€¢ Execute tool calling loop
    â€¢ Process response
    â†“
Return ChatResult with metadata
```

**Key Code:**

```typescript
/**
 * Handles a single chat request:
 * 1) Selects intent based on participant and command
 * 2) Invokes intent via DefaultIntentRequestHandler
 * 
 * Created fresh for each user message.
 */
export class ChatParticipantRequestHandler {
    
    public readonly conversation: Conversation;
    private readonly location: ChatLocation;
    private readonly stream: ChatResponseStream;
    private readonly documentContext: IDocumentContext | undefined;
    private readonly intentDetector: IntentDetector;
    private readonly turn: Turn;
    private readonly chatTelemetry: ChatTelemetryBuilder;
    
    constructor(
        private readonly rawHistory: ReadonlyArray<ChatRequestTurn | ChatResponseTurn>,
        private request: ChatRequest,
        stream: ChatResponseStream,
        private readonly token: CancellationToken,
        private readonly chatAgentArgs: IChatAgentArgs, // { agentName, agentId, intentId }
        private readonly onPaused: Event<boolean>,
        @IInstantiationService private readonly _instantiationService: IInstantiationService,
        @IEndpointProvider private readonly _endpointProvider: IEndpointProvider,
        @ICommandService private readonly _commandService: ICommandService,
        @IIgnoreService private readonly _ignoreService: IIgnoreService,
        @IIntentService private readonly _intentService: IIntentService,
        @IConversationStore private readonly _conversationStore: IConversationStore,
        @ITabsAndEditorsService tabsAndEditorsService: ITabsAndEditorsService,
        @ILogService private readonly _logService: ILogService,
        @IAuthenticationService private readonly _authService: IAuthenticationService,
        @IAuthenticationChatUpgradeService private readonly _authenticationUpgradeService: IAuthenticationChatUpgradeService,
    ) {
        // Determine location (panel, editor, terminal, notebook)
        this.location = this.getLocation(request);
        
        // Create intent detector for telemetry
        this.intentDetector = this._instantiationService.createInstance(IntentDetector);
        
        // Filter stream to avoid duplicate references in editor
        this.stream = stream;
        if (request.location2 instanceof ChatRequestEditorData) {
            const documentUri = request.location2.document.uri;
            this.stream = ChatResponseStreamImpl.filter(stream, part => {
                if (part instanceof ChatResponseReferencePart || 
                    part instanceof ChatResponseProgressPart2) {
                    const uri = URI.isUri(part.value) ? part.value : part.value.uri;
                    return !isEqual(uri, documentUri);
                }
                return true;
            });
        }
        
        // Reconstruct conversation from VS Code history
        const { turns, sessionId } = _instantiationService.invokeFunction(
            accessor => addHistoryToConversation(accessor, rawHistory)
        );
        normalizeSummariesOnRounds(turns);
        const actualSessionId = sessionId ?? generateUuid();
        
        // Infer document context from editor (for inline chat)
        this.documentContext = IDocumentContext.inferDocumentContext(
            request, 
            tabsAndEditorsService.activeTextEditor, 
            turns
        );
        
        // Initialize telemetry
        this.chatTelemetry = this._instantiationService.createInstance(
            ChatTelemetryBuilder,
            Date.now(),
            actualSessionId,
            this.documentContext,
            turns.length === 0, // isFirstTurn
            this.request
        );
        
        // Create turn for this request
        const latestTurn = Turn.fromRequest(
            this.chatTelemetry.telemetryMessageId,
            this.request
        );
        
        this.conversation = new Conversation(actualSessionId, turns.concat(latestTurn));
        this.turn = latestTurn;
    }
    
    /**
     * Determine chat location from VS Code's location API.
     */
    private getLocation(request: ChatRequest): ChatLocation {
        if (request.location2 instanceof ChatRequestEditorData) {
            return ChatLocation.Editor;
        } else if (request.location2 instanceof ChatRequestNotebookData) {
            return ChatLocation.Notebook;
        }
        
        // Fallback to deprecated location API
        switch (request.location) {
            case VSChatLocation.Editor:
                return ChatLocation.Editor;
            case VSChatLocation.Panel:
                return ChatLocation.Panel;
            case VSChatLocation.Terminal:
                return ChatLocation.Terminal;
            default:
                return ChatLocation.Other;
        }
    }
    
    /**
     * Main entry point - processes the request and returns result.
     */
    async getResult(): Promise<ICopilotChatResult> {
        
        // Check if we need permissive auth for workspace tools
        if (await this._shouldAskForPermissiveAuth()) {
            return {
                metadata: {
                    modelMessageId: this.turn.responseId ?? '',
                    responseId: this.turn.id,
                    sessionId: this.conversation.sessionId,
                    agentId: this.chatAgentArgs.agentId,
                    command: this.request.command,
                }
            };
        }
        
        this._logService.trace(
            `[${ChatLocation.toStringShorter(this.location)}] chat request received`
        );
        
        try {
            // Sanitize variables - respect .copilotignore
            this.request = await this.sanitizeVariables();
            
            // Get command details if intent was specified
            const command = this.chatAgentArgs.intentId ?
                this._commandService.getCommand(this.chatAgentArgs.intentId, this.location) :
                undefined;
            
            // Validate command usage
            let result = this.checkCommandUsage(command);
            
            if (!result) {
                // Normal case: select intent and invoke it
                const history = this.conversation.turns.slice(0, -1);
                const intent = await this.selectIntent(command, history);
                
                let chatResult: Promise<ChatResult>;
                
                // Check if intent has custom handler
                if (typeof intent.handleRequest === 'function') {
                    // Intent implements its own handling (rare)
                    chatResult = intent.handleRequest(
                        this.conversation, 
                        this.request, 
                        this.stream, 
                        this.token, 
                        this.documentContext, 
                        this.chatAgentArgs.agentName, 
                        this.location, 
                        this.chatTelemetry, 
                        this.onPaused
                    );
                } else {
                    // Standard path: use DefaultIntentRequestHandler
                    const intentHandler = this._instantiationService.createInstance(
                        DefaultIntentRequestHandler, 
                        intent, 
                        this.conversation, 
                        this.request, 
                        this.stream, 
                        this.token, 
                        this.documentContext, 
                        this.location, 
                        this.chatTelemetry, 
                        undefined, // options
                        this.onPaused
                    );
                    chatResult = intentHandler.getResult();
                }
                
                // Collect intent detection telemetry
                if (!this.request.isParticipantDetected) {
                    this.intentDetector.collectIntentDetectionContextInternal(
                        this.turn.request.message,
                        this.request.enableCommandDetection ? intent.id : 'none',
                        new ChatVariablesCollection(this.request.references),
                        this.location,
                        history,
                        this.documentContext?.document
                    );
                }
                
                result = await chatResult;
                
                // Add endpoint information to result
                const endpoint = await this._endpointProvider.getChatEndpoint(this.request);
                result.details = this._authService.copilotToken?.isNoAuthUser ?
                    `${endpoint.name}` :
                    `${endpoint.name} â€¢ ${endpoint.multiplier ?? 0}x`;
            }
            
            // Store conversation for future retrieval
            this._conversationStore.addConversation(this.turn.id, this.conversation);
            
            // Add fixed metadata shape to result
            mixin(result, {
                metadata: {
                    modelMessageId: this.turn.responseId ?? '',
                    responseId: this.turn.id,
                    sessionId: this.conversation.sessionId,
                    agentId: this.chatAgentArgs.agentId,
                    command: this.request.command
                }
            } satisfies ICopilotChatResult, true);
            
            return result as ICopilotChatResult;
            
        } catch (err) {
            throw err;
        }
    }
    
    /**
     * Select the appropriate intent for this request.
     * 
     * Priority:
     * 1. Command explicitly specified (e.g., /explain)
     * 2. Location-specific heuristics (inline chat)
     * 3. Unknown intent (uses LLM to determine intent)
     */
    private async selectIntent(
        command: CommandDetails | undefined, 
        history: Turn[]
    ): Promise<IIntent> {
        
        // If command specified, use its intent
        if (command?.intent) {
            return command.intent;
        }
        
        // Special logic for inline chat (editor location)
        if (this.location === ChatLocation.Editor) {
            let preferredIntent: Intent | undefined;
            
            // First-turn heuristics
            if (this.documentContext && 
                this.request.attempt === 0 && 
                history.length === 0) {
                
                const selection = this.documentContext.selection;
                const line = this.documentContext.document.lineAt(selection.start.line);
                
                // Empty line with cursor â†’ suggest generate
                if (selection.isEmpty && line.text.trim() === '') {
                    preferredIntent = Intent.Generate;
                }
                // Multi-line selection â†’ suggest edit
                else if (!selection.isEmpty && 
                         selection.start.line !== selection.end.line) {
                    preferredIntent = Intent.Edit;
                }
            }
            
            if (preferredIntent) {
                return this._intentService.getIntent(preferredIntent, this.location) 
                    ?? this._intentService.unknownIntent;
            }
        }
        
        // Default: use unknown intent (will detect from user message)
        return this._intentService.unknownIntent;
    }
    
    /**
     * Check if command was used correctly (not empty when args required).
     */
    private checkCommandUsage(command: CommandDetails | undefined): ChatResult | undefined {
        if (command?.intent && 
            !(command.intent.commandInfo?.allowsEmptyArgs ?? true) && 
            !this.turn.request.message) {
            
            const commandAgent = getAgentForIntent(command.intent.id as Intent, this.location);
            let usage = '';
            if (commandAgent) {
                usage = `@${commandAgent.agent} `;
                if (commandAgent.command) {
                    usage += ` /${commandAgent.command}`;
                }
                usage += ` ${command.details}`;
            }
            
            const message = l10n.t(
                `Please specify a question when using this command.\n\nUsage: {0}`, 
                usage
            );
            const chatResult = { errorDetails: { message } };
            this.turn.setResponse(
                TurnStatus.Error, 
                { type: 'meta', message }, 
                undefined, 
                chatResult
            );
            return chatResult;
        }
    }
    
    /**
     * Filter out references to ignored files (.copilotignore, .gitignore).
     */
    private async sanitizeVariables(): Promise<ChatRequest> {
        const variablePromises = this.request.references.map(async (ref) => {
            const uri = isLocation(ref.value) ? ref.value.uri : 
                        URI.isUri(ref.value) ? ref.value : 
                        undefined;
            
            if (!uri || uri.scheme === Schemas.untitled) {
                return ref;
            }
            
            let removeVariable;
            try {
                removeVariable = await this._ignoreService.isCopilotIgnored(uri);
            } catch {
                // File might not exist or be virtual - that's OK
            }
            
            if (removeVariable && ref.range) {
                // Also sanitize the user message (remove file path)
                this.turn.request.message = 
                    this.turn.request.message.slice(0, ref.range[0]) + 
                    this.turn.request.message.slice(ref.range[1]);
            }
            
            return removeVariable ? null : ref;
        });
        
        const newVariables = coalesce(await Promise.all(variablePromises));
        return { ...this.request, references: newVariables };
    }
    
    /**
     * Check if we need to prompt for permissive auth.
     * Required when using workspace tools without full repo access.
     */
    private async _shouldAskForPermissiveAuth(): Promise<boolean> {
        // User already confirmed auth
        const findConfirmRequest = this.request.acceptedConfirmationData?.find(
            ref => ref?.authPermissionPrompted
        );
        if (findConfirmRequest) {
            this.request = await this._authenticationUpgradeService.handleConfirmationRequest(
                this.stream, 
                this.request, 
                this.rawHistory
            );
            this.turn.request.message = this.request.prompt;
            return false;
        }
        
        // Check if using workspace tool
        const isWorkspaceCall = 
            this.request.toolReferences.some(ref => ref.name === ContributedToolName.Codebase) ||
            this.chatAgentArgs.agentId === getChatParticipantIdFromName(workspaceAgentName);
        
        // Show confirmation if needed
        if (isWorkspaceCall && 
            await this._authenticationUpgradeService.shouldRequestPermissiveSessionUpgrade()) {
            this._authenticationUpgradeService.showPermissiveSessionUpgradeInChat(
                this.stream, 
                this.request
            );
            return true;
        }
        
        return false;
    }
}

/**
 * Helper: Reconstruct Conversation object from VS Code's chat history.
 * VS Code stores history as ChatRequestTurn[] | ChatResponseTurn[],
 * but we need our internal Conversation/Turn model.
 */
export function addHistoryToConversation(
    accessor: ServicesAccessor, 
    history: ReadonlyArray<ChatRequestTurn | ChatResponseTurn>
): { turns: Turn[]; sessionId: string | undefined } {
    
    const instaService = accessor.get(IInstantiationService);
    const turns: Turn[] = [];
    let sessionId: string | undefined;
    let previousChatRequestTurn: ChatRequestTurn | undefined;
    
    for (const entry of history) {
        if (entry instanceof ChatRequestTurn) {
            previousChatRequestTurn = entry;
        } else {
            // Try to find existing Turn from conversation store
            const existingTurn = instaService.invokeFunction(
                findExistingTurnFromVSCodeChatHistoryTurn, 
                entry
            );
            
            if (existingTurn) {
                turns.push(existingTurn);
            } else if (previousChatRequestTurn) {
                // Create Turn from request/response pair
                const deserializedTurn = instaService.invokeFunction(
                    createTurnFromVSCodeChatHistoryTurns, 
                    previousChatRequestTurn, 
                    entry
                );
                previousChatRequestTurn = undefined;
                turns.push(deserializedTurn);
            }
            
            // Extract session ID from metadata
            const copilotResult = entry.result as ICopilotChatResultIn;
            if (typeof copilotResult.metadata?.sessionId === 'string') {
                sessionId = copilotResult.metadata.sessionId;
            }
        }
    }
    
    return { turns, sessionId };
}
```

**Key Insights:**

1. **Ephemeral Handler**: A new `ChatParticipantRequestHandler` is created for **every chat message**. It's not a long-lived object.

2. **History Reconstruction**: VS Code doesn't maintain our `Conversation` object across requests - we rebuild it from `context.history` each time.

3. **Smart Intent Selection**: The handler uses heuristics (location, selection state, first turn) to guess user intent before even calling the LLM.

4. **Security**: `.copilotignore` and `.gitignore` are enforced at this layer - ignored files never reach the LLM.

5. **Telemetry**: Tracks everything - intent detection accuracy, model usage, context size, etc.

6. **Error Handling**: Validates command usage and provides helpful error messages before invoking expensive LLM calls.

---

#### Layer 3: DefaultIntentRequestHandler - Intent Execution

**File: `src/extension/prompt/node/defaultIntentRequestHandler.ts`**

This is where the **actual work happens**. The `DefaultIntentRequestHandler` is the execution engine for most intents in GitHub Copilot. It:

**Core Responsibilities:**
1. **Intent Invocation**: Calls `IIntent.invoke()` to get the intent-specific configuration
2. **Prompt Building**: Uses `@vscode/prompt-tsx` to build structured prompts with context
3. **Tool Calling Loop**: Manages multi-turn agent execution (tool calls, results, follow-ups)
4. **Response Processing**: Handles streaming responses, applies edits, shows progress
5. **Error Management**: Graceful handling of quota limits, cancellations, content filtering
6. **Telemetry**: Comprehensive tracking of request lifecycle and outcomes

**What is an Intent?**

An **Intent** (`IIntent` interface) represents a specific capability that Copilot can perform:

```typescript
export interface IIntent {
    readonly id: string;                    // e.g., 'explain', 'fix', 'generate'
    readonly description: string;           // User-facing description
    readonly locations: ChatLocation[];     // Where it can be used (panel, editor)
    readonly commandInfo?: IIntentSlashCommandInfo; // Slash command config
    
    /**
     * Called when this intent is selected.
     * Returns an IIntentInvocation that configures:
     * - How to build the prompt
     * - Which tools are available
     * - How to process the response
     */
    invoke(context: IIntentInvocationContext): Promise<IIntentInvocation>;
    
    /**
     * Optional: custom request handler (bypasses default flow)
     */
    handleRequest?(
        conversation: Conversation,
        request: vscode.ChatRequest,
        stream: vscode.ChatResponseStream,
        token: CancellationToken,
        documentContext: IDocumentContext | undefined,
        agentName: string,
        location: ChatLocation,
        chatTelemetry: ChatTelemetryBuilder,
        onPaused: Event<boolean>,
    ): Promise<vscode.ChatResult>;
}

export interface IIntentInvocation {
    readonly intent: IIntent;
    readonly location: ChatLocation;
    readonly endpoint: IChatEndpoint;        // Which model to use
    
    /**
     * Build the prompt (system message, user messages, context).
     * Uses @vscode/prompt-tsx for structured prompt construction.
     */
    buildPrompt(
        context: IBuildPromptContext,
        progress: vscode.Progress<...>,
        token: CancellationToken
    ): Promise<IBuildPromptResult>;
    
    /**
     * Optional: specify which tools are available for this intent.
     */
    getAvailableTools?(): vscode.LanguageModelToolInformation[] | undefined;
    
    /**
     * Optional: custom response processing (parse special formats, etc.)
     */
    processResponse?(/* ... */): AsyncIterable<IResponsePart>;
    
    /**
     * Optional: modify error messages for this intent.
     */
    modifyErrorDetails?(
        errorDetails: vscode.ChatErrorDetails, 
        response: ChatResponse
    ): vscode.ChatErrorDetails;
}
```

**Examples of Intents:**
- **ExplainIntent**: Explains selected code with context from surrounding functions
- **FixIntent**: Fixes errors using diagnostic information
- **GenerateIntent**: Generates new code with inferred types and patterns
- **EditCode2Intent** (Plan Mode): Handles complex multi-file edits in `ChatLocation.EditingSession` (Copilot Edits)
- **TestIntent**: Creates unit tests with proper mocking and assertions
- **WorkspaceIntent**: Answers questions using codebase search and semantic analysis

Each intent customizes:
- System prompt (e.g., "You are an expert code explainer")
- Context gathering (e.g., include related functions for explain, include test framework for tests)
- Available tools (e.g., workspace search for @workspace, terminal commands for @terminal)
- Response format (e.g., code blocks vs markdown)

**Execution Flow:**

```
DefaultIntentRequestHandler.getResult()
    â†“
1. Invoke intent
    intent.invoke() â†’ returns IIntentInvocation
    â†“
2. Handle confirmations (if needed)
    User might need to confirm destructive actions
    â†“
3. Run tool calling loop
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Tool Calling Loop (Agent Mode)         â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ 1. Build Prompt                   â”‚  â”‚
    â”‚  â”‚    â€¢ System message               â”‚  â”‚
    â”‚  â”‚    â€¢ Conversation history         â”‚  â”‚
    â”‚  â”‚    â€¢ Context (files, diagnostics) â”‚  â”‚
    â”‚  â”‚    â€¢ Tool definitions             â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚           â†“                              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ 2. Call Language Model            â”‚  â”‚
    â”‚  â”‚    â€¢ Send request                 â”‚  â”‚
    â”‚  â”‚    â€¢ Stream response chunks       â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚           â†“                              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ 3. Process Response               â”‚  â”‚
    â”‚  â”‚    â€¢ Parse markdown               â”‚  â”‚
    â”‚  â”‚    â€¢ Extract tool calls           â”‚  â”‚
    â”‚  â”‚    â€¢ Show progress                â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚           â†“                              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ 4. Execute Tools (if any)         â”‚  â”‚
    â”‚  â”‚    â€¢ Run file_search              â”‚  â”‚
    â”‚  â”‚    â€¢ Read files                   â”‚  â”‚
    â”‚  â”‚    â€¢ Execute commands             â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚           â†“                              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ 5. Check if done                  â”‚  â”‚
    â”‚  â”‚    â€¢ No more tool calls?          â”‚  â”‚
    â”‚  â”‚    â€¢ Hit iteration limit?         â”‚  â”‚
    â”‚  â”‚    â€¢ User cancelled?              â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚           â†“                              â”‚
    â”‚    Loop back to step 1 with tool resultsâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
4. Process final result
    â€¢ Handle errors (quota, filtering, etc.)
    â€¢ Set turn response with status
    â€¢ Add telemetry
    â†“
Return ChatResult
```

**Key Code:**

```typescript
/**
 * Handles intent execution with tool calling support.
 * Created once per request by ChatParticipantRequestHandler.
 */
export class DefaultIntentRequestHandler {
    
    private readonly turn: Turn;
    private _editSurvivalTracker: IEditSurvivalTrackingSession;
    private _loop!: DefaultToolCallingLoop;
    
    constructor(
        private readonly intent: IIntent,
        private readonly conversation: Conversation,
        protected readonly request: ChatRequest,
        protected readonly stream: ChatResponseStream,
        private readonly token: CancellationToken,
        protected readonly documentContext: IDocumentContext | undefined,
        private readonly location: ChatLocation,
        private readonly chatTelemetryBuilder: ChatTelemetryBuilder,
        private readonly handlerOptions: IDefaultIntentRequestHandlerOptions = { 
            maxToolCallIterations: 15 
        },
        private readonly onPaused: Event<boolean>,
        @IInstantiationService private readonly _instantiationService: IInstantiationService,
        @IConversationOptions private readonly options: IConversationOptions,
        @ITelemetryService private readonly _telemetryService: ITelemetryService,
        @ILogService private readonly _logService: ILogService,
        @ISurveyService private readonly _surveyService: ISurveyService,
        @IRequestLogger private readonly _requestLogger: IRequestLogger,
        @IEditSurvivalTrackerService private readonly _editSurvivalTrackerService: IEditSurvivalTrackerService,
        @IAuthenticationService private readonly _authenticationService: IAuthenticationService,
    ) {
        this.turn = conversation.getLatestTurn();
    }
    
    /**
     * Main entry point - execute the intent and return result.
     */
    async getResult(): Promise<ChatResult> {
        
        // Handle tool call limit cancellation
        if (isToolCallLimitCancellation(this.request)) {
            this.stream.markdown(l10n.t("Let me know if there's anything else I can help with!"));
            return {};
        }
        
        try {
            if (this.token.isCancellationRequested) {
                return CanceledResult;
            }
            
            // Step 1: Invoke the intent to get configuration
            this._logService.trace('Processing intent');
            const intentInvocation = await this.intent.invoke({ 
                location: this.location, 
                documentContext: this.documentContext, 
                request: this.request 
            });
            if (this.token.isCancellationRequested) {
                return CanceledResult;
            }
            this._logService.trace('Processed intent');
            
            // Store intent invocation metadata
            this.turn.setMetadata(new IntentInvocationMetadata(intentInvocation));
            
            // Step 2: Handle confirmations (destructive actions)
            const confirmationResult = await this.handleConfirmationsIfNeeded();
            if (confirmationResult) {
                return confirmationResult;
            }
            
            // Step 3: Run the tool calling loop
            const resultDetails = await this._requestLogger.captureInvocation(
                this.request, 
                () => this.runWithToolCalling(intentInvocation)
            );
            
            let chatResult = resultDetails.chatResult || {};
            
            // Signal usage for surveys
            this._surveyService.signalUsage(
                `${this.location === ChatLocation.Editor ? 'inline' : 'panel'}.${this.intent.id}`, 
                this.documentContext?.document.languageId
            );
            
            // Extract final response message
            const responseMessage = resultDetails.toolCallRounds.at(-1)?.response ?? '';
            
            // Add tool call metadata
            const metadataFragment: Partial<IResultMetadata> = {
                toolCallRounds: resultDetails.toolCallRounds,
                toolCallResults: this._collectRelevantToolCallResults(
                    resultDetails.toolCallRounds, 
                    resultDetails.toolCallResults
                ),
            };
            mixin(chatResult, { metadata: metadataFragment }, true);
            
            // Step 4: Process the final result
            const baseModelTelemetry = createTelemetryWithId();
            chatResult = await this.processResult(
                resultDetails.response, 
                responseMessage, 
                chatResult, 
                metadataFragment, 
                baseModelTelemetry, 
                resultDetails.toolCallRounds
            );
            
            // Allow intent to modify error details
            if (chatResult.errorDetails && intentInvocation.modifyErrorDetails) {
                chatResult.errorDetails = intentInvocation.modifyErrorDetails(
                    chatResult.errorDetails, 
                    resultDetails.response
                );
            }
            
            // Show warning if files were ignored
            if (resultDetails.hadIgnoredFiles) {
                this.stream.markdown(HAS_IGNORED_FILES_MESSAGE);
            }
            
            return chatResult;
            
        } catch (err) {
            if (err instanceof ToolCallCancelledError) {
                this.turn.setResponse(
                    TurnStatus.Cancelled, 
                    { message: err.message, type: 'meta' }, 
                    undefined, 
                    {}
                );
                return {};
            } else if (isCancellationError(err)) {
                return CanceledResult;
            } else if (err instanceof EmptyPromptError) {
                return {};
            }
            
            // Log and report unexpected errors
            this._logService.error(err);
            this._telemetryService.sendGHTelemetryException(err, 'Error');
            
            const errorMessage = (<Error>err).message;
            const chatResult = { errorDetails: { message: errorMessage } };
            this.turn.setResponse(
                TurnStatus.Error, 
                { message: errorMessage, type: 'meta' }, 
                undefined, 
                chatResult
            );
            return chatResult;
        }
    }
    
    /**
     * Create response stream participants for tracking and processing.
     * These intercept the response stream to:
     * - Track code blocks (for stests)
     * - Track edit survival (did user keep the AI edits?)
     * - Linkify URLs and file paths
     * - Collect telemetry on emitted components
     */
    private makeResponseStreamParticipants(
        intentInvocation: IIntentInvocation
    ): ResponseStreamParticipant[] {
        
        const participants: ResponseStreamParticipant[] = [];
        
        // 1. Track code blocks
        participants.push(stream => {
            const codeBlockTrackingResponseStream = 
                this._instantiationService.createInstance(
                    CodeBlockTrackingChatResponseStream, 
                    stream, 
                    intentInvocation.codeblocksRepresentEdits
                );
            return ChatResponseStreamImpl.spy(
                codeBlockTrackingResponseStream,
                v => v,
                () => {
                    const codeBlocksMetaData = codeBlockTrackingResponseStream.finish();
                    this.turn.setMetadata(codeBlocksMetaData);
                }
            );
        });
        
        // 2. Track edit survival (inline chat only)
        if (this.documentContext && this.location === ChatLocation.Editor) {
            participants.push(stream => {
                const firstTurnWithAIEditCollector = 
                    this.conversation.turns.find(
                        turn => turn.getMetadata(CopilotInteractiveEditorResponse)?.editSurvivalTracker
                    );
                
                this._editSurvivalTracker = 
                    firstTurnWithAIEditCollector?.getMetadata(CopilotInteractiveEditorResponse)?.editSurvivalTracker 
                    ?? this._editSurvivalTrackerService.initialize(this.documentContext.document.document);
                
                return ChatResponseStreamImpl.spy(stream, value => {
                    if (value instanceof ChatResponseTextEditPart) {
                        this._editSurvivalTracker.collectAIEdits(value.edits);
                    }
                });
            });
        }
        
        // 3. Linkify URLs and file paths
        if (!intentInvocation.linkification?.disable) {
            participants.push(stream => {
                const linkStream = this._instantiationService.createInstance(
                    ResponseStreamWithLinkification, 
                    { requestId: this.turn.id, references: this.turn.references }, 
                    stream, 
                    intentInvocation.linkification?.additionaLinkifiers ?? [], 
                    this.token
                );
                return ChatResponseStreamImpl.spy(linkStream, p => p, () => {
                    this._loop.telemetry.markAddedLinks(linkStream.totalAddedLinkCount);
                });
            });
        }
        
        // 4. General telemetry
        participants.push(stream => ChatResponseStreamImpl.spy(stream, (part) => {
            if (part instanceof ChatResponseMarkdownPart) {
                this._loop.telemetry.markEmittedMarkdown(part.value);
            }
            if (part instanceof ChatResponseTextEditPart) {
                this._loop.telemetry.markEmittedEdits(part.uri, part.edits);
            }
        }));
        
        return participants;
    }
    
    /**
     * Run the tool calling loop.
     * This is the core agent execution engine.
     */
    private async runWithToolCalling(
        intentInvocation: IIntentInvocation
    ): Promise<IInternalRequestResult> {
        
        const store = new DisposableStore();
        
        // Create tool calling loop
        const loop = this._loop = store.add(
            this._instantiationService.createInstance(
                DefaultToolCallingLoop,
                {
                    conversation: this.conversation,
                    intent: this.intent,
                    invocation: intentInvocation,
                    toolCallLimit: this.handlerOptions.maxToolCallIterations,
                    onHitToolCallLimit: this.handlerOptions.confirmOnMaxToolIterations !== false
                        ? ToolCallLimitBehavior.Confirm 
                        : ToolCallLimitBehavior.Stop,
                    request: this.request,
                    documentContext: this.documentContext,
                    streamParticipants: this.makeResponseStreamParticipants(intentInvocation),
                    temperature: this.handlerOptions.temperature ?? this.options.temperature,
                    location: this.location,
                    overrideRequestLocation: this.handlerOptions.overrideRequestLocation,
                    interactionContext: this.documentContext?.document.uri,
                    responseProcessor: typeof intentInvocation.processResponse === 'function' 
                        ? intentInvocation as IResponseProcessor 
                        : undefined,
                },
                this.chatTelemetryBuilder,
            )
        );
        
        // Wire up events
        store.add(Event.once(loop.onDidBuildPrompt)(
            this._sendInitialChatReferences, 
            this
        ));
        
        const responseHandlers: Promise<unknown>[] = [];
        store.add(loop.onDidReceiveResponse(res => {
            const promise = this._onDidReceiveResponse(res);
            responseHandlers.push(promise);
            return promise;
        }, this));
        
        const pauseCtrl = store.add(new PauseController(this.onPaused, this.token));
        
        try {
            // Run the loop!
            const result = await loop.run(this.stream, pauseCtrl);
            
            // Send tool calling telemetry
            if (!result.round.toolCalls.length || 
                result.response.type !== ChatFetchResponseType.Success) {
                loop.telemetry.sendToolCallingTelemetry(
                    result.toolCallRounds, 
                    result.availableTools, 
                    this.token.isCancellationRequested ? 'cancelled' : result.response.type
                );
            }
            
            result.chatResult ??= {};
            if ((result.chatResult.metadata as IResultMetadata)?.maxToolCallsExceeded) {
                loop.telemetry.sendToolCallingTelemetry(
                    result.toolCallRounds, 
                    result.availableTools, 
                    'maxToolCalls'
                );
            }
            
            // Add all metadata
            result.chatResult = this.resultWithMetadatas(result.chatResult);
            return { ...result, lastRequestTelemetry: loop.telemetry };
            
        } finally {
            await Promise.allSettled(responseHandlers);
            store.dispose();
        }
    }
    
    /**
     * Process the final result and determine status.
     */
    private async processResult(
        fetchResult: ChatResponse, 
        responseMessage: string, 
        chatResult: ChatResult, 
        metadataFragment: Partial<IResultMetadata>, 
        baseModelTelemetry: ConversationalBaseTelemetryData, 
        rounds: IToolCallRound[]
    ): Promise<ChatResult> {
        
        switch (fetchResult.type) {
            case ChatFetchResponseType.Success:
                return await this.processSuccessfulFetchResult(
                    responseMessage, 
                    fetchResult.requestId, 
                    chatResult, 
                    baseModelTelemetry, 
                    rounds
                );
                
            case ChatFetchResponseType.OffTopic:
                this.stream.markdown(this.options.rejectionMessage);
                this.turn.setResponse(
                    TurnStatus.OffTopic, 
                    { message: this.options.rejectionMessage, type: 'offtopic-detection' }, 
                    baseModelTelemetry.properties.messageId, 
                    {}
                );
                return {};
                
            case ChatFetchResponseType.Canceled:
            case ChatFetchResponseType.QuotaExceeded:
            case ChatFetchResponseType.RateLimited:
            case ChatFetchResponseType.BadRequest:
            case ChatFetchResponseType.NetworkError:
            case ChatFetchResponseType.Failed:
            case ChatFetchResponseType.Filtered:
            case ChatFetchResponseType.PromptFiltered:
            case ChatFetchResponseType.AgentUnauthorized:
            case ChatFetchResponseType.AgentFailedDependency:
            case ChatFetchResponseType.Length:
            case ChatFetchResponseType.NotFound:
            case ChatFetchResponseType.Unknown:
            case ChatFetchResponseType.ExtensionBlocked:
                const errorDetails = getErrorDetailsFromChatFetchError(
                    fetchResult, 
                    (await this._authenticationService.getCopilotToken()).copilotPlan
                );
                const result = { errorDetails, metadata: metadataFragment };
                this.turn.setResponse(
                    this.getStatusFromFetchResult(fetchResult), 
                    undefined, 
                    baseModelTelemetry.properties.messageId, 
                    result
                );
                return result;
                
            case ChatFetchResponseType.InvalidStatefulMarker:
                throw new Error('unreachable'); // Retried within endpoint
        }
    }
    
    private async processSuccessfulFetchResult(
        appliedText: string, 
        requestId: string, 
        chatResult: ChatResult, 
        baseModelTelemetry: ConversationalBaseTelemetryData, 
        rounds: IToolCallRound[]
    ): Promise<ChatResult> {
        
        // Validate we got a non-empty response
        if (appliedText.length === 0 && !rounds.some(r => r.toolCalls.length)) {
            const message = l10n.t(
                'The model unexpectedly did not return a response. Request ID: {0}', 
                requestId
            );
            this.turn.setResponse(
                TurnStatus.Error, 
                { type: 'meta', message }, 
                baseModelTelemetry.properties.messageId, 
                chatResult
            );
            return { errorDetails: { message } };
        }
        
        // Success!
        this.turn.setResponse(
            TurnStatus.Success, 
            { type: 'model', message: appliedText }, 
            baseModelTelemetry.properties.messageId, 
            chatResult
        );
        
        baseModelTelemetry.markAsDisplayed();
        
        // Send detailed telemetry
        sendModelMessageTelemetry(
            this._telemetryService,
            this.conversation,
            this.location,
            appliedText,
            requestId,
            this.documentContext?.document,
            baseModelTelemetry,
            this.getModeName()
        );
        
        return chatResult;
    }
    
    private getModeName(): string {
        return this.request.modeInstructions2 ? 'custom' :
            this.intent.id === 'editAgent' ? 'agent' :
            (this.intent.id === 'edit' || this.intent.id === 'edit2') ? 'edit' :
            'ask';
    }
}
```

**Tool Calling Loop (Agent Mode):**

The `DefaultToolCallingLoop` class (also in this file) implements the agent execution loop:

```typescript
class DefaultToolCallingLoop extends ToolCallingLoop<IDefaultToolLoopOptions> {
    public telemetry!: ChatTelemetry;
    
    constructor(
        options: IDefaultToolLoopOptions,
        telemetryBuilder: ChatTelemetryBuilder,
        @IInstantiationService instantiationService: IInstantiationService,
        @ILogService logService: ILogService,
        @IRequestLogger requestLogger: IRequestLogger,
        @IEndpointProvider endpointProvider: IEndpointProvider,
        @IAuthenticationChatUpgradeService authenticationChatUpgradeService: IAuthenticationChatUpgradeService,
        @ITelemetryService telemetryService: ITelemetryService,
        @IToolGroupingService private readonly toolGroupingService: IToolGroupingService,
        @IExperimentationService private readonly _experimentationService: IExperimentationService,
        @ICopilotTokenStore private readonly _copilotTokenStore: ICopilotTokenStore,
    ) {
        super(options, instantiationService, endpointProvider, logService, requestLogger, authenticationChatUpgradeService, telemetryService);
        
        // Initialize telemetry when prompt is built
        this._register(this.onDidBuildPrompt(({ result, tools, promptTokenLength }) => {
            this.telemetry = telemetryBuilder.makeRequest(
                options.intent!,
                options.location,
                options.conversation,
                result.messages,
                promptTokenLength,
                result.references,
                options.invocation.endpoint,
                result.telemetryData ?? [],
                tools.length
            );
        }));
    }
    
    // Inherits from ToolCallingLoop:
    // - buildPrompt(): Build prompt with conversation history + context + tool definitions
    // - sendRequest(): Send to language model
    // - processResponse(): Parse streaming response
    // - executeTools(): Run tool calls (file_search, read_file, etc.)
    // - checkTermination(): Decide if we're done or need another iteration
}
```

**Key Insights:**

1. **Separation of Concerns**: 
   - `IIntent` defines WHAT to do (explain, fix, generate)
   - `IIntentInvocation` defines HOW to do it (prompts, tools, processing)
   - `DefaultIntentRequestHandler` orchestrates the execution

2. **Flexible Architecture**: Intents can:
   - Provide custom `buildPrompt()` logic (different system messages, context gathering)
   - Specify which tools are available (`getAvailableTools()`)
   - Process responses specially (`processResponse()` for structured output)
   - Implement their own handler entirely (`handleRequest()`)

3. **Tool Calling as Default**: The loop supports multi-turn agent execution out of the box. Most intents just define prompts and let the agent figure out what tools to call.

4. **Comprehensive Error Handling**: 24+ error types handled gracefully with user-friendly messages.

5. **Telemetry Everywhere**: Every step tracked for product insights and A/B testing.

6. **Production Hardened**: Handles quota exhaustion, rate limits, content filtering, cancellation, network errors, etc.

---

#### Summary: Three-Layer Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: ChatAgents                                            â”‚
â”‚  Responsibility: Registration & Routing                         â”‚
â”‚  â€¢ Creates participants (@copilot, @workspace, etc.)            â”‚
â”‚  â€¢ Handles auth, quota, privacy                                 â”‚
â”‚  â€¢ Routes to Layer 2                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: ChatParticipantRequestHandler                         â”‚
â”‚  Responsibility: Intent Selection & Context                     â”‚
â”‚  â€¢ Selects intent (explain, fix, generate)                      â”‚
â”‚  â€¢ Gathers context (files, diagnostics, selections)             â”‚
â”‚  â€¢ Sanitizes variables (.copilotignore)                         â”‚
â”‚  â€¢ Routes to Layer 3                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: DefaultIntentRequestHandler                           â”‚
â”‚  Responsibility: Intent Execution                               â”‚
â”‚  â€¢ Invokes intent (IIntent.invoke())                            â”‚
â”‚  â€¢ Builds prompt with @vscode/prompt-tsx                        â”‚
â”‚  â€¢ Runs tool calling loop (agent mode)                          â”‚
â”‚  â€¢ Processes streaming responses                                â”‚
â”‚  â€¢ Handles errors and telemetry                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why This Matters for Your Extension:**

- **Start Simple**: You don't need all three layers! For basic participants, use the simple handler pattern from `chat-sample`
- **Scale Gradually**: As complexity grows, adopt patterns from GitHub Copilot's architecture
- **Intent System**: If you have multiple capabilities, consider an intent-based architecture
- **Tool Calling**: For agent-like behavior, use the Language Model API's built-in tool calling
- **Context Management**: Learn from how Copilot gathers and sanitizes context
- **Error Handling**: Study the comprehensive error handling patterns

---

#### VS Code Core - Chat Service

**File: `src/vs/workbench/contrib/chat/common/chatService.ts`**

This is VS Code's core orchestration service for chat interactions. It sits between the chat UI and participant implementations.

**Responsibilities:**
1. **Message Parsing**: Breaks down user input into components (@participant, /command, variables, plain text)
2. **Participant Resolution**: Finds the appropriate chat participant to handle the request
3. **Context Gathering**: Collects relevant workspace context (files, selections, diagnostics)
4. **Request Lifecycle**: Manages request creation, execution, cancellation, and retry
5. **Session Management**: Maintains conversation history across multiple turns

**Service Architecture:**
```
ChatWidget (UI)
    â†“ user sends message
ChatService (orchestrator)
    â†“ parse and route
ChatAgentService (participant registry)
    â†“ invoke handler
Extension's ChatRequestHandler
    â†“ use model
LanguageModelService
```

**Key Methods:**
- `sendRequest()`: Main entry point for new chat messages
- `resendRequest()`: Handles "regenerate response" button clicks
- `cancelCurrentRequestForSession()`: Stops in-progress requests

**Why This Matters:**
Understanding ChatService helps you:
- Debug why your participant isn't being called
- See what context is automatically provided
- Understand request lifecycle for telemetry
- Know when to use `context.history` vs. maintaining your own state

```typescript
/**
 * Core service managing chat sessions, requests, and participant orchestration.
 * This is the central hub for all chat activity in VS Code.
 */
export interface IChatService {
    sendRequest(
        sessionResource: URI,
        message: string,
        options?: IChatSendRequestOptions
    ): Promise<IChatSendRequestData | undefined>;
    
    resendRequest(
        request: IChatRequestModel,
        options?: IChatSendRequestOptions
    ): Promise<void>;
    
    cancelCurrentRequestForSession(sessionResource: URI): void;
}

export class ChatService implements IChatService {
    async sendRequest(
        sessionResource: URI,
        message: string,
        options?: IChatSendRequestOptions
    ): Promise<IChatSendRequestData | undefined> {
        // 1. Parse message (extract @participant, /command, variables)
        const parsed = this.chatParserService.parseChatRequest(message);
        
        // 2. Get agent (participant) handler
        const agent = this.chatAgentService.getAgent(parsed.agentId);
        if (!agent) {
            throw new Error(`Chat participant not found: ${parsed.agentId}`);
        }
        
        // 3. Gather context (files, editor selection, workspace info)
        const context = await this.gatherContext(parsed, options);
        
        // 4. Create request model
        const request = model.addRequest(parsed, context, attempt);
        
        // 5. Invoke agent handler
        const result = await agent.invoke(request, progress, history, token);
        
        // 6. Update model with result
        model.setResponse(request, result);
        
        return { requestId: request.id };
    }
}
```

#### Chat Agent Registration (Main Thread)

**File: `src/vs/workbench/api/browser/mainThreadChatAgents2.ts`**

This class is the main thread bridge for chat participant registration. It validates and registers participant implementations from extensions.

**Why This Validation Exists:**

VS Code requires chat participants to be **declared in package.json** before they can be registered. This ensures:
1. Users can see available participants before activating the extension
2. VS Code can show participant metadata (name, icon, commands) without loading the extension
3. Security: prevents malicious extensions from hijacking existing participant names
4. Performance: lazy loading - extension only activates when participant is actually used

**package.json Declaration Example:**
```json
{
  "contributes": {
    "chatParticipants": [{
      "id": "myext.agent",
      "name": "agent",
      "description": "Helps with coding tasks",
      "commands": [
        {
          "name": "fix",
          "description": "Fix code issues"
        },
        {
          "name": "explain",
          "description": "Explain code"
        }
      ]
    }]
  }
}
```

**Registration Flow:**
```
Extension activates
    â†“
Calls vscode.chat.createChatParticipant('myext.agent', handler)
    â†“ RPC
MainThreadChatAgents2.$registerAgent(handle, id, metadata)
    â†“ Validates
ChatAgentService.getAgentsByName(id) - checks package.json
    â†“ If valid
ChatAgentService.updateAgent(id, implementation)
    â†“
Ready to handle user requests
```

```typescript
/**
 * Main thread side of chat agent (participant) registration.
 * Bridges between extension host and core chat services.
 */
@extHostNamedCustomer(MainContext.MainThreadChatAgents2)
export class MainThreadChatAgents2 {
    /**
     * Called when extension calls vscode.chat.createChatParticipant().
     * Validates declaration and registers the implementation.
     */
    async $registerAgent(
        handle: number,                          // Unique handle for this registration
        extension: ExtensionIdentifier,           // Which extension owns this
        id: string,                               // Participant ID (e.g., "github.copilot")
        metadata: IExtensionChatAgentMetadata     // Name, description, etc.
    ): Promise<void> {
        // CRITICAL: Verify agent is declared in package.json
        // This prevents runtime registration of undeclared participants
        const staticAgents = this.chatAgentService.getAgentsByName(id);
        if (!staticAgents.length) {
            throw new Error(
                `chatParticipant must be declared in package.json contributes.chatParticipants: ${id}`
            );
        }
        
        // Register implementation
        const impl: IChatAgentImplementation = {
            invoke: async (request, progress, history, token) => {
                // Bridge to extension host
                return await this._proxy.$invokeAgent(
                    handle,
                    request,
                    { history },
                    progress,
                    token
                );
            },
            
            provideFollowups: async (request, result, history, token) => {
                return await this._proxy.$provideFollowups(
                    handle,
                    request,
                    result,
                    history,
                    token
                );
            }
        };
        
        this.chatAgentService.updateAgent(id, impl);
    }
}
```

---

### 3. Agent Mode / Tool Calling

#### Overview

Tool Calling (also called Function Calling) enables language models to invoke external functions during their response generation. This transforms passive chat assistants into **autonomous agents** that can perform actions.

**Purpose:**
Instead of just generating text, models can:
- Search your workspace for relevant code
- Read file contents
- Execute terminal commands
- Create/edit files
- Run tests
- Query APIs
- Multi-step reasoning (use one tool result to decide next tool)

**How It Works (The Agent Loop):**
```
1. User: "Create a REST API for user management"
   â†“
2. Model thinks: "I need to see the project structure first"
   â†’ Returns: ToolCall(name="list_files", args={path: "./src"})
   â†“
3. VS Code executes tool, gets: ["controllers/", "models/", "routes/"]
   â†’ Sends result back to model
   â†“
4. Model thinks: "I'll create the user controller"
   â†’ Returns: ToolCall(name="create_file", args={path: "./src/controllers/user.ts", content: "..."})
   â†“
5. VS Code creates file
   â†’ Model continues or finishes
```

**Models Supporting Tools:**
- âœ… GPT-4, GPT-4 Turbo, GPT-4o (OpenAI)
- âœ… Claude 3 Opus, Claude 3.5 Sonnet (Anthropic)
- âœ… Gemini 1.5 Pro (Google)
- âŒ GPT-3.5 Turbo (limited support)
- âŒ Most open-source models (unless specifically trained)

**Use Cases:**

1. **Code Generation Agents**:
   - Analyze existing code â†’ Generate new code â†’ Run tests â†’ Fix errors
   
2. **Debugging Assistants**:
   - Read error logs â†’ Find relevant code â†’ Suggest fixes â†’ Apply changes
   
3. **Refactoring Agents**:
   - Analyze code quality â†’ Identify issues â†’ Apply refactorings â†’ Verify tests pass
   
4. **Documentation Generators**:
   - Read source files â†’ Extract APIs â†’ Generate markdown â†’ Create examples

5. **Multi-Step Workflows**:
   - User: "Deploy to staging"
   - Agent: Run tests â†’ Build â†’ Check environment â†’ Deploy â†’ Verify health

**Architecture:**
```
Chat Participant
    â†“ calls model with tools
Language Model
    â†“ returns tool call
VS Code Tool Registry
    â†“ executes tool
Tool Implementation (your extension or built-in)
    â†“ returns result
Language Model (continues reasoning)
```

#### Key Interfaces

**vscode.proposed.chatParticipantAdditions.d.ts:**

```typescript
/**
 * Represents a tool call request from the language model.
 * When the model wants to use a tool, it returns this instead of text.
 */
export interface LanguageModelToolCallPart {
    /**
     * Unique identifier for this specific tool invocation.
     * Used to match tool results back to the original call.
     */
    readonly callId: string;
    
    /**
     * Name of the tool to invoke (e.g., "search_workspace", "create_file")
     */
    readonly name: string;
    
    /**
     * Arguments to pass to the tool, as JSON object.
     * Must conform to the tool's inputSchema.
     * Example: { "path": "./src", "query": "class User" }
     */
    readonly input: object;
}

/**
 * Tool execution result sent back to the model.
 * The model uses this information to continue its reasoning.
 */
export interface LanguageModelToolResultPart {
    /**
     * Must match the callId from LanguageModelToolCallPart.
     * This links the result to the original tool call.
     */
    readonly callId: string;
    
    /**
     * The result content. Can be text or structured data.
     * Model will interpret this to make next decision.
     * Example: "Found 5 files matching query", or file contents
     */
    readonly content: (LanguageModelTextPart | LanguageModelPromptTsxPart)[];
}

/**
 * Definition of a tool that can be called by language models.
 * Tools extend what AI models can do beyond just text generation.
 */
export interface LanguageModelChatTool {
    /**
     * Unique tool identifier. Use descriptive names like "search_files", "run_tests".
     * Models use this name when deciding which tool to call.
     */
    readonly name: string;
    
    /**
     * Human-readable description of what the tool does.
     * CRITICAL: The model reads this to decide when to use your tool.
     * Be specific and clear!
     * 
     * Good: "Searches the workspace for files matching a glob pattern and returns file paths"
     * Bad: "Search files"
     */
    readonly description: string;
    
    /**
     * JSON Schema defining the tool's input parameters.
     * The model generates arguments conforming to this schema.
     * 
     * Example:
     * {
     *   type: 'object',
     *   properties: {
     *     query: { type: 'string', description: 'Search query' },
     *     maxResults: { type: 'number', default: 10 }
     *   },
     *   required: ['query']
     * }
     */
    readonly inputSchema?: object;  // JSON Schema
    
    /**
     * Implementation function that executes when model calls this tool.
     * This is YOUR code that performs the actual work.
     * 
     * @param options - Contains input arguments and context
     * @param token - Cancellation token
     * @returns Tool result (text, data, or error)
     */
    invoke(options: LanguageModelToolInvocationOptions, token: CancellationToken): 
        ProviderResult<LanguageModelToolResult>;
}

export namespace lm {
    export const tools: readonly LanguageModelChatTool[];
    
    export function invokeTool(
        name: string,
        options: LanguageModelToolInvocationOptions,
        token: CancellationToken
    ): Thenable<LanguageModelToolResult>;
}
```

#### Implementation Example: Complete Tool Definition

This example shows how to create a complete, production-ready tool that searches the workspace.

**Tool Purpose:** Allow the AI model to search for files in the workspace by name or pattern.

**When Model Uses This:**
- User asks: "Find all TypeScript test files"
- User asks: "Show me components related to authentication"
- Agent needs to understand project structure before making changes

```typescript
/**
 * Tool that searches for files in the workspace.
 * Used by AI models to explore project structure and find relevant files.
 */
const searchTool: vscode.LanguageModelChatTool = {
    // Tool identifier - model uses this in tool calls
    name: 'search_workspace',
    
    // Description - CRITICAL for model decision-making
    // The better your description, the more accurately the model uses your tool
    description: 'Search for files and code in the workspace. ' +
                 'Use this to find files by name, extension, or path pattern. ' +
                 'Returns a list of matching file paths. ' +
                 'Useful before reading files or understanding project structure.',
    
    // JSON Schema - defines expected input format
    inputSchema: {
        type: 'object',
        properties: {
            query: { 
                type: 'string', 
                description: 'Search query - can be filename, extension, or text to match in path'
            },
            filePattern: { 
                type: 'string', 
                description: 'Optional glob pattern (e.g., "**/*.ts", "src/**")',
                default: '**/*'
            },
            maxResults: {
                type: 'number',
                description: 'Maximum number of results to return',
                default: 20,
                minimum: 1,
                maximum: 100
            }
        },
        required: ['query']  // query is mandatory, others are optional
    },
    
    // Implementation - the actual work happens here
    invoke: async (options, token) => {
        // Extract and validate inputs
        const { query, filePattern = '**/*', maxResults = 20 } = options.input as any;
        
        try {
            // Check cancellation before expensive operation
            if (token.isCancellationRequested) {
                return new vscode.LanguageModelToolResult([
                    new vscode.LanguageModelTextPart('Search cancelled')
                ]);
            }
            
            // Perform search using VS Code API
            const results = await vscode.workspace.findFiles(
                filePattern,
                '**/node_modules/**',  // Exclude node_modules
                maxResults
            );
            
            // Filter by query string
            const filtered = results.filter(uri => 
                uri.path.toLowerCase().includes(query.toLowerCase())
            ).slice(0, maxResults);
            
            // Format results for model consumption
            if (filtered.length === 0) {
                return new vscode.LanguageModelToolResult([
                    new vscode.LanguageModelTextPart(
                        `No files found matching "${query}" with pattern "${filePattern}"`
                    )
                ]);
            }
            
            // Return formatted list of files
            const fileList = filtered
                .map(uri => vscode.workspace.asRelativePath(uri))
                .join('\\n');
            
            return new vscode.LanguageModelToolResult([
                new vscode.LanguageModelTextPart(
                    `Found ${filtered.length} file(s) matching "${query}":\\n${fileList}`
                )
            ]);
            
        } catch (error) {
            // Handle errors gracefully - model needs to know what went wrong
            return new vscode.LanguageModelToolResult([
                new vscode.LanguageModelTextPart(
                    `Error searching workspace: ${error.message}`
                )
            ]);
        }
    }
};

// Register tool globally (accessible to all participants)
// Tool names should be prefixed with extension ID to avoid conflicts
vscode.lm.registerTool('myext_search', searchTool);

/**
 * Using Tools in Chat Participants
 * 
 * This example shows how to create a chat participant that uses tools
 * for autonomous, multi-step operations (agent mode).
 */

// Chat participant handler with tool support
const handler: vscode.ChatRequestHandler = async (request, context, stream, token) => {
    // Show initial progress
    stream.progress('Analyzing your request...');
    
    // Prepare messages for model with system instructions
    const messages = [
        vscode.LanguageModelChatMessage.User(
            'You are a helpful coding assistant. Use available tools to help the user.'
        ),
        vscode.LanguageModelChatMessage.User(request.prompt)
    ];
    
    // Get available tools (can be registered by any extension)
    const tools = [
        vscode.lm.tools.find(t => t.name === 'myext_search'),
        vscode.lm.tools.find(t => t.name === 'vscode_readFile'),
        vscode.lm.tools.find(t => t.name === 'vscode_createFile')
    ].filter(Boolean);
    
    // Send request WITH tools enabled - this enables agent mode
    // The model will now autonomously decide when to use tools
    const chatResponse = await request.model.sendRequest(
        messages,
        {
            tools: tools,
            // Auto: model decides when to use tools (recommended)
            // Required: model MUST use at least one tool
            toolMode: vscode.LanguageModelChatToolMode.Auto
        },
        token
    );
    
    // Process streaming response with tool calls
    // This loop handles both text responses and tool invocations
    for await (const part of chatResponse.stream) {
        if (part instanceof vscode.LanguageModelTextPart) {
            // Regular text response from model - stream to UI
            stream.markdown(part.value);
            
        } else if (part instanceof vscode.LanguageModelToolCallPart) {
            // Model wants to use a tool! This is the agent behavior.
            
            // Show progress to user
            stream.prepareToolInvocation(part.name);
            stream.progress(`Using tool: ${part.name}...`);
            
            // Invoke the tool
            // VS Code finds the registered tool and executes it
            const result = await vscode.lm.invokeTool(
                part.name,
                {
                    input: part.input,              // Tool arguments from model
                    requestId: request.id,
                    toolInvocationToken: request.toolInvocationToken
                },
                token
            );
            
            // Optionally show tool result to user
            stream.markdown(`\\n*Tool result: ${result.content[0].value}*\\n`);
            
            // IMPORTANT: The tool result is automatically sent back to the model
            // Model continues reasoning with this new information
            // This enables multi-turn agent loops:
            //   1. Model calls search_workspace â†’ gets file list
            //   2. Model calls read_file on interesting files â†’ gets contents
            //   3. Model generates response based on file contents
        }
    }
    
    return { metadata: { toolsUsed: tools.map(t => t.name) } };
};
```

**Built-in VS Code Tools:**

VS Code provides several built-in tools that any chat participant can use:

| Tool Name | Description | Use Case |
|-----------|-------------|----------|
| `vscode_readFile` | Read file contents | Understanding existing code |
| `vscode_createFile` | Create new files | Code generation |
| `vscode_editFile` | Modify existing files | Refactoring, bug fixes |
| `vscode_executeCommand` | Run VS Code commands | Trigger actions (format, run tests) |
| `vscode_searchWorkspace` | Semantic search | Find relevant code |
| `vscode_getDiagnostics` | Get errors/warnings | Debugging assistance |

**Best Practices for Tool Design:**

1. **Descriptive Names**: Use `verb_noun` pattern (`search_files`, `run_tests`, not `search` or `tool1`)
2. **Clear Descriptions**: Models read these - be specific about what the tool does and when to use it
3. **Detailed Schema**: More schema detail = better model understanding and fewer errors
4. **Error Handling**: Always return meaningful errors - model needs to understand what went wrong
5. **Performance**: Keep tools fast (<2 seconds) or model may timeout
6. **Idempotency**: Same input should give same output when possible
7. **Security**: Validate all inputs - models can make mistakes or be manipulated
8. **Prefix Names**: Use `yourext_toolname` to avoid conflicts with other extensions

**Example Multi-Step Agent Workflow:**

```
User: "Fix the bug in UserController"
    â†“
Model: "I need to find the file first"
    â†’ Calls: search_workspace({ query: "UserController" })
    â† Result: "Found: src/controllers/UserController.ts"
    â†“
Model: "Let me read the file"
    â†’ Calls: read_file({ path: "src/controllers/UserController.ts" })
    â† Result: [file contents with bug]
    â†“
Model: "I see the bug on line 42. Let me fix it"
    â†’ Calls: edit_file({ path: "...", line: 42, newCode: "..." })
    â† Result: "File updated successfully"
    â†“
Model: "I've fixed the null pointer bug by adding a null check"
```

---

## Request Flow: Method-Level Sequence

### Scenario 1: User sends "@copilot explain this code" in Chat Panel

```
User Input â†’ Chat Panel UI
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ChatWidget (src/vs/workbench/contrib/chat/browser/chatWidget.ts)â”‚
â”‚    - acceptInput(message: string)                                 â”‚
â”‚    - Parse: participant=copilot, command=undefined, prompt="explain..."â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ Call chatService.sendRequest()
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. ChatService (src/vs/workbench/contrib/chat/common/chatServiceImpl.ts)â”‚
â”‚    async sendRequest(sessionResource, message, options) {         â”‚
â”‚      // Parse message                                             â”‚
â”‚      const parsed = this.chatParserService.parseChatRequest(msg); â”‚
â”‚      // Result: { agentId: 'github.copilot', prompt: '...', ...} â”‚
â”‚                                                                    â”‚
â”‚      // Get agent                                                 â”‚
â”‚      const agent = this.chatAgentService.getAgent(parsed.agentId);â”‚
â”‚                                                                    â”‚
â”‚      // Gather context                                            â”‚
â”‚      const context = await this.gatherContext(parsed, options);   â”‚
â”‚      // Collects: active editor, selection, diagnostics, etc.    â”‚
â”‚                                                                    â”‚
â”‚      // Create request                                            â”‚
â”‚      const request = model.addRequest(parsed, context, attempt);  â”‚
â”‚                                                                    â”‚
â”‚      // Invoke agent                                              â”‚
â”‚      const result = await agent.invoke(request, progress, ...);   â”‚
â”‚    }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ Call agent.invoke()
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ChatAgentService (src/vs/workbench/contrib/chat/common/chatAgents.ts)â”‚
â”‚    agent.invoke(request, progress, history, token) {              â”‚
â”‚      // This calls the extension-registered implementation        â”‚
â”‚      return this._impl.invoke(request, progress, history, token); â”‚
â”‚    }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ IPC to Extension Host
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. MainThreadChatAgents2 (mainThreadChatAgents2.ts)              â”‚
â”‚    // Bridge between main thread and extension host              â”‚
â”‚    invoke: async (request, progress, history, token) => {         â”‚
â”‚      return await this._proxy.$invokeAgent(handle, request, ...); â”‚
â”‚    }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ RPC Call
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. ExtHostChatAgents2 (Extension Host)                           â”‚
â”‚    $invokeAgent(handle, request, context, progress, token) {      â”‚
â”‚      const agent = this._agents.get(handle);                      â”‚
â”‚      return agent.handler(request, context, stream, token);       â”‚
â”‚    }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ Call user's handler
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. YOUR EXTENSION - Chat Participant Handler                     â”‚
â”‚    async handler(request, context, stream, token) {               â”‚
â”‚      // Build prompt with context                                 â”‚
â”‚      const messages = [                                           â”‚
â”‚        vscode.LanguageModelChatMessage.User(systemPrompt),        â”‚
â”‚        vscode.LanguageModelChatMessage.User(request.prompt)       â”‚
â”‚      ];                                                            â”‚
â”‚                                                                    â”‚
â”‚      // Call language model                                       â”‚
â”‚      const response = await request.model.sendRequest(            â”‚
â”‚        messages,                                                   â”‚
â”‚        { tools: myTools },                                         â”‚
â”‚        token                                                       â”‚
â”‚      );                                                            â”‚
â”‚                                                                    â”‚
â”‚      // Stream response to UI                                     â”‚
â”‚      for await (const fragment of response.text) {                â”‚
â”‚        stream.markdown(fragment);  â—„â”€â”€â”€ Updates UI in real-time  â”‚
â”‚      }                                                             â”‚
â”‚                                                                    â”‚
â”‚      return { metadata: { ... } };                                â”‚
â”‚    }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ Call vscode.lm.sendRequest()
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. ExtHostLanguageModels (Extension Host)                        â”‚
â”‚    sendRequest(messages, options, token) {                        â”‚
â”‚      // Find provider for selected model                          â”‚
â”‚      const provider = this._providers.get(modelId);               â”‚
â”‚                                                                    â”‚
â”‚      // Call main thread via proxy                                â”‚
â”‚      return this._proxy.$sendChatRequest(                         â”‚
â”‚        modelId, messages, options, progress, token                â”‚
â”‚      );                                                            â”‚
â”‚    }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ RPC Call to Main Thread
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. MainThreadLanguageModels (Main Thread)                        â”‚
â”‚    $sendChatRequest(modelId, messages, options, progress, token) {â”‚
â”‚      return this.languageModelsService.sendChatRequest(           â”‚
â”‚        modelId, messages, options, progress, token                â”‚
â”‚      );                                                            â”‚
â”‚    }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ Call service
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. LanguageModelsService (languageModels.ts)                     â”‚
â”‚    sendChatRequest(modelId, messages, options, progress, token) { â”‚
â”‚      const provider = this._providers.get(modelId);               â”‚
â”‚      return provider.provideChatResponse(                         â”‚
â”‚        messages, options, progress, token                         â”‚
â”‚      );                                                            â”‚
â”‚    }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ Back to Extension Host via RPC
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10. YOUR EXTENSION - LanguageModelProvider                       â”‚
â”‚     provideLanguageModelChatResponse(...) {                       â”‚
â”‚       // 1. Get auth token                                        â”‚
â”‚       const token = await this.auth.getSession();                 â”‚
â”‚                                                                    â”‚
â”‚       // 2. Call Azure OpenAI / GitHub Models / etc.             â”‚
â”‚       const response = await fetch(endpoint, {                    â”‚
â”‚         method: 'POST',                                           â”‚
â”‚         headers: { 'Authorization': `Bearer ${token}` },          â”‚
â”‚         body: JSON.stringify({ model, messages, stream: true })   â”‚
â”‚       });                                                          â”‚
â”‚                                                                    â”‚
â”‚       // 3. Stream response via progress.report()                â”‚
â”‚       for await (const chunk of response.body) {                  â”‚
â”‚         const data = parseSSE(chunk);                             â”‚
â”‚         progress.report(new LanguageModelTextPart(data.content)); â”‚
â”‚         // â–² This flows back through all layers to Chat UI       â”‚
â”‚       }                                                            â”‚
â”‚     }                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ Progress updates flow back
                â–¼
        Chat UI renders streaming response
```

---

### Scenario 2: User types prompt with Agent model selected

This scenario shows the complete interaction when a user types "Create a REST API for user management" in the chat with Claude 3.5 Sonnet (Agent) selected as the model.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ Types: "Create a REST API for user management"
      â”‚ Model selected: Claude 3.5 Sonnet (copilot/claude-3-5-sonnet)
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chat Panel UI (ChatWidget)                                              â”‚
â”‚ src/vs/workbench/contrib/chat/browser/chatWidget.ts                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ acceptInput(message: string)                                            â”‚
â”‚   â””â”€> Parse input                                                       â”‚
â”‚       â€¢ participant: (none - using default)                             â”‚
â”‚       â€¢ prompt: "Create a REST API for user management"                 â”‚
â”‚       â€¢ model: claude-3-5-sonnet                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ chatService.sendRequest(sessionUri, message, options)
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChatService                                                             â”‚
â”‚ src/vs/workbench/contrib/chat/common/chatServiceImpl.ts                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ async sendRequest(sessionResource, message, options) {                  â”‚
â”‚   1. Parse message                                                      â”‚
â”‚      parsed = chatParserService.parseChatRequest(message)               â”‚
â”‚      Result: {                                                          â”‚
â”‚        agentId: undefined,  // No @participant specified                â”‚
â”‚        command: undefined,   // No /command                             â”‚
â”‚        prompt: "Create a REST API...",                                  â”‚
â”‚        model: "claude-3-5-sonnet"                                       â”‚
â”‚      }                                                                   â”‚
â”‚                                                                          â”‚
â”‚   2. Resolve agent (use default since no @participant)                  â”‚
â”‚      agent = chatAgentService.getDefaultAgent()                         â”‚
â”‚      // Returns: @copilot participant                                   â”‚
â”‚                                                                          â”‚
â”‚   3. Gather context                                                     â”‚
â”‚      context = {                                                        â”‚
â”‚        activeEditor: vscode.window.activeTextEditor,                    â”‚
â”‚        selection: editor.selection,                                     â”‚
â”‚        diagnostics: vscode.languages.getDiagnostics(),                  â”‚
â”‚        workspaceFiles: vscode.workspace.workspaceFolders,               â”‚
â”‚        history: previousChatMessages                                    â”‚
â”‚      }                                                                   â”‚
â”‚                                                                          â”‚
â”‚   4. Create request model                                               â”‚
â”‚      request = chatModel.addRequest(parsed, context, attempt=0)         â”‚
â”‚      requestId = generateUuid()                                         â”‚
â”‚                                                                          â”‚
â”‚   5. Invoke agent                                                       â”‚
â”‚      result = await agent.invoke(request, progress, history, token)     â”‚
â”‚ }                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ agent.invoke(request, progress, history, token)
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChatAgentService                                                        â”‚
â”‚ src/vs/workbench/contrib/chat/common/chatAgents.ts                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ agent.invoke(request, progress, history, token) {                       â”‚
â”‚   // Delegate to extension-registered implementation                    â”‚
â”‚   return this._implementation.invoke(request, progress, history, token);â”‚
â”‚ }                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ IPC: Call ExtHost proxy
                      â”‚ $invokeAgent(handle, request, context, progress, token)
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MainThreadChatAgents2 (Main Thread - UI Process)                       â”‚
â”‚ src/vs/workbench/api/browser/mainThreadChatAgents2.ts                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Implementation registered for @copilot:                                 â”‚
â”‚ {                                                                        â”‚
â”‚   invoke: async (request, progress, history, token) => {                â”‚
â”‚     // Bridge to extension host                                         â”‚
â”‚     this._pendingProgress.set(request.requestId, {                      â”‚
â”‚       progress,      // Callback for streaming updates                  â”‚
â”‚       chatSession    // Current chat session                            â”‚
â”‚     });                                                                  â”‚
â”‚                                                                          â”‚
â”‚     return await this._proxy.$invokeAgent(                              â”‚
â”‚       handle: 123,  // Extension handle                                 â”‚
â”‚       request: {                                                         â”‚
â”‚         id: "req-uuid-123",                                             â”‚
â”‚         sessionId: "session-uuid-456",                                  â”‚
â”‚         prompt: "Create a REST API...",                                 â”‚
â”‚         model: "claude-3-5-sonnet",                                     â”‚
â”‚         attempt: 0,                                                      â”‚
â”‚         references: [...context.files],                                 â”‚
â”‚         locationData: { editor, selection }                             â”‚
â”‚       },                                                                 â”‚
â”‚       context: { history: [...] },                                      â”‚
â”‚       progress: progressCallback,                                       â”‚
â”‚       token                                                             â”‚
â”‚     );                                                                   â”‚
â”‚   }                                                                      â”‚
â”‚ }                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ RPC to Extension Host
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ExtHostChatAgents2 (Extension Host Process - Node.js/Web Worker)       â”‚
â”‚ src/vs/workbench/api/node/extHostChatAgents2.ts                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ $invokeAgent(handle, request, context, progress, token) {               â”‚
â”‚   const agent = this._agents.get(handle);  // Get @copilot             â”‚
â”‚                                                                          â”‚
â”‚   // Create stream adapter                                              â”‚
â”‚   const stream = {                                                       â”‚
â”‚     markdown: (text) => progress.report({ kind: 'markdown', text }),    â”‚
â”‚     progress: (msg) => progress.report({ kind: 'progress', msg }),      â”‚
â”‚     reference: (uri) => progress.report({ kind: 'reference', uri }),    â”‚
â”‚     button: (cmd) => progress.report({ kind: 'button', command: cmd })  â”‚
â”‚   };                                                                     â”‚
â”‚                                                                          â”‚
â”‚   // Call user's handler                                                â”‚
â”‚   return agent.requestHandler(request, context, stream, token);         â”‚
â”‚ }                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ Call extension's chat participant handler
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GitHub Copilot Extension - Chat Participant Handler                    â”‚
â”‚ vscode-copilot-chat/src/extension/conversation/                        â”‚
â”‚   copilotChatParticipant.ts                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ async handler(request, context, stream, token) {                        â”‚
â”‚   // 1. Show progress                                                   â”‚
â”‚   stream.progress('Analyzing your request...');                         â”‚
â”‚                                                                          â”‚
â”‚   // 2. Gather additional context                                       â”‚
â”‚   const workspace = await analyzeWorkspace();                           â”‚
â”‚   const codeContext = await getRelevantCode(request.locationData);      â”‚
â”‚                                                                          â”‚
â”‚   // 3. Build prompt with system instructions                           â”‚
â”‚   const systemPrompt = `You are GitHub Copilot, an AI coding assistant.â”‚
â”‚     Current task: Help create a REST API.                               â”‚
â”‚     Workspace: ${workspace.name}                                        â”‚
â”‚     Available tools: create_file, edit_file, run_command`;              â”‚
â”‚                                                                          â”‚
â”‚   const messages = [                                                    â”‚
â”‚     vscode.LanguageModelChatMessage.User(systemPrompt),                 â”‚
â”‚     vscode.LanguageModelChatMessage.User(request.prompt),               â”‚
â”‚     ...formatHistory(context.history)                                   â”‚
â”‚   ];                                                                     â”‚
â”‚                                                                          â”‚
â”‚   // 4. Select model (already specified by user)                        â”‚
â”‚   const [model] = await vscode.lm.selectChatModels({                    â”‚
â”‚     id: request.model  // "claude-3-5-sonnet"                           â”‚
â”‚   });                                                                    â”‚
â”‚                                                                          â”‚
â”‚   // 5. Prepare tools for agent mode                                    â”‚
â”‚   const tools = [                                                        â”‚
â”‚     vscode.lm.tools.find(t => t.name === 'vscode_createFile'),          â”‚
â”‚     vscode.lm.tools.find(t => t.name === 'vscode_editFile'),            â”‚
â”‚     vscode.lm.tools.find(t => t.name === 'vscode_runCommand'),          â”‚
â”‚     vscode.lm.tools.find(t => t.name === 'vscode_searchWorkspace')      â”‚
â”‚   ].filter(Boolean);                                                     â”‚
â”‚                                                                          â”‚
â”‚   // 6. Send request to language model with tools enabled               â”‚
â”‚   stream.progress('Thinking...');                                       â”‚
â”‚                                                                          â”‚
â”‚   const chatResponse = await model.sendRequest(                         â”‚
â”‚     messages,                                                            â”‚
â”‚     {                                                                    â”‚
â”‚       tools: tools,                                                      â”‚
â”‚       toolMode: vscode.LanguageModelChatToolMode.Auto                   â”‚
â”‚     },                                                                   â”‚
â”‚     token                                                               â”‚
â”‚   );                                                                     â”‚
â”‚                                                                          â”‚
â”‚   // 7. Process streaming response                                      â”‚
â”‚   for await (const part of chatResponse.stream) {                       â”‚
â”‚     if (part instanceof vscode.LanguageModelTextPart) {                 â”‚
â”‚       stream.markdown(part.value);  // â—„â”€ Streams to UI                â”‚
â”‚                                                                          â”‚
â”‚     } else if (part instanceof vscode.LanguageModelToolCallPart) {      â”‚
â”‚       // Model wants to use a tool                                      â”‚
â”‚       stream.progress(`Using tool: ${part.name}`);                      â”‚
â”‚       stream.prepareToolInvocation(part.name);                          â”‚
â”‚                                                                          â”‚
â”‚       // Execute tool                                                   â”‚
â”‚       const result = await vscode.lm.invokeTool(                        â”‚
â”‚         part.name,                                                       â”‚
â”‚         {                                                                â”‚
â”‚           input: part.input,                                            â”‚
â”‚           requestId: request.id,                                        â”‚
â”‚           toolInvocationToken: request.toolInvocationToken              â”‚
â”‚         },                                                               â”‚
â”‚         token                                                           â”‚
â”‚       );                                                                 â”‚
â”‚                                                                          â”‚
â”‚       // Send tool result back to model for next iteration              â”‚
â”‚       // (VS Code handles this in subsequent model call)                â”‚
â”‚     }                                                                    â”‚
â”‚   }                                                                      â”‚
â”‚                                                                          â”‚
â”‚   return { metadata: { modelUsed: 'claude-3-5-sonnet' } };              â”‚
â”‚ }                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ model.sendRequest(messages, options, token)
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ExtHostLanguageModels (Extension Host)                                 â”‚
â”‚ src/vs/workbench/api/common/extHostLanguageModels.ts                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ async sendRequest(messages, options, token) {                           â”‚
â”‚   // Find model info                                                    â”‚
â”‚   const modelInfo = this._models.get('claude-3-5-sonnet');              â”‚
â”‚   // { vendor: 'copilot', family: 'claude-3', version: '3.5-sonnet' }  â”‚
â”‚                                                                          â”‚
â”‚   // Validate tool support                                              â”‚
â”‚   if (options.tools && !modelInfo.supportsTools) {                      â”‚
â”‚     throw new Error('Model does not support tools');                    â”‚
â”‚   }                                                                      â”‚
â”‚                                                                          â”‚
â”‚   // Create progress adapter for streaming                              â”‚
â”‚   const progressAdapter = new LanguageModelResponseStream();            â”‚
â”‚                                                                          â”‚
â”‚   // Call main thread via RPC                                           â”‚
â”‚   await this._proxy.$sendChatRequest(                                   â”‚
â”‚     modelId: 'copilot/claude-3-5-sonnet',                               â”‚
â”‚     messages: messages.map(m => ({                                      â”‚
â”‚       role: m.role,  // 'user' or 'assistant'                           â”‚
â”‚       content: m.content                                                â”‚
â”‚     })),                                                                 â”‚
â”‚     options: {                                                           â”‚
â”‚       tools: options.tools?.map(t => ({                                 â”‚
â”‚         name: t.name,                                                    â”‚
â”‚         description: t.description,                                     â”‚
â”‚         inputSchema: t.inputSchema                                      â”‚
â”‚       })),                                                               â”‚
â”‚       toolMode: 'auto',                                                  â”‚
â”‚       requestInitiator: 'chat-participant'                              â”‚
â”‚     },                                                                   â”‚
â”‚     progressToken: progressAdapter.token,                               â”‚
â”‚     token                                                               â”‚
â”‚   );                                                                     â”‚
â”‚                                                                          â”‚
â”‚   return progressAdapter.getResponse();                                 â”‚
â”‚ }                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ RPC to Main Thread
                      â”‚ $sendChatRequest(modelId, messages, options, progress, token)
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MainThreadLanguageModels (Main Thread)                                 â”‚
â”‚ src/vs/workbench/api/browser/mainThreadLanguageModels.ts               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ async $sendChatRequest(modelId, messages, options, progress, token) {   â”‚
â”‚   // Delegate to language models service                                â”‚
â”‚   return await this.languageModelsService.sendChatRequest(              â”‚
â”‚     modelId: 'copilot/claude-3-5-sonnet',                               â”‚
â”‚     messages,                                                            â”‚
â”‚     options,                                                             â”‚
â”‚     progress: (part) => {                                               â”‚
â”‚       // Forward progress back to extension host                        â”‚
â”‚       this._proxy.$reportProgress(progress, part);                      â”‚
â”‚     },                                                                   â”‚
â”‚     token                                                               â”‚
â”‚   );                                                                     â”‚
â”‚ }                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ Call service
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LanguageModelsService (VS Code Core)                                   â”‚
â”‚ src/vs/workbench/contrib/chat/common/languageModels.ts                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ async sendChatRequest(modelId, messages, options, progress, token) {    â”‚
â”‚   // 1. Find provider for model                                         â”‚
â”‚   const provider = this._providers.get('copilot');                      â”‚
â”‚   if (!provider) {                                                       â”‚
â”‚     throw new Error('Language model provider not found: copilot');      â”‚
â”‚   }                                                                      â”‚
â”‚                                                                          â”‚
â”‚   // 2. Get model info                                                  â”‚
â”‚   const model = provider.getModel('claude-3-5-sonnet');                 â”‚
â”‚   if (!model) {                                                          â”‚
â”‚     throw new Error('Model not found: claude-3-5-sonnet');              â”‚
â”‚   }                                                                      â”‚
â”‚                                                                          â”‚
â”‚   // 3. Check quotas and permissions                                    â”‚
â”‚   await this.checkQuota(provider, model);                               â”‚
â”‚                                                                          â”‚
â”‚   // 4. Call provider's implementation                                  â”‚
â”‚   return await provider.provideChatResponse(                            â”‚
â”‚     model,                                                               â”‚
â”‚     messages,                                                            â”‚
â”‚     options,                                                             â”‚
â”‚     progress,                                                            â”‚
â”‚     token                                                               â”‚
â”‚   );                                                                     â”‚
â”‚ }                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ Back to Extension Host (provider is implemented there)
                      â”‚ RPC: $provideChatResponse(handle, model, messages, options, progress, token)
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GitHub Copilot Extension - LanguageModelAccess                         â”‚
â”‚ vscode-copilot-chat/src/extension/conversation/vscode-node/            â”‚
â”‚   languageModelAccess.ts                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ async _provideLanguageModelChatResponse(                                â”‚
â”‚   model: { id: 'claude-3-5-sonnet', ... },                              â”‚
â”‚   messages: readonly LanguageModelChatRequestMessage[],                 â”‚
â”‚   options: ProvideLanguageModelChatResponseOptions,                     â”‚
â”‚   progress: Progress<LanguageModelResponsePart>,                        â”‚
â”‚   token: CancellationToken                                              â”‚
â”‚ ): Promise<void> {                                                       â”‚
â”‚                                                                          â”‚
â”‚   // 1. Get authentication token                                        â”‚
â”‚   const session = await this.authenticationService.getSession(          â”‚
â”‚     ['user:email', 'copilot']                                           â”‚
â”‚   );                                                                     â”‚
â”‚   const authToken = session.accessToken;                                â”‚
â”‚                                                                          â”‚
â”‚   // 2. Get endpoint URL                                                â”‚
â”‚   const endpoint = await this.endpointService.getEndpoint();            â”‚
â”‚   // Returns: "https://api.githubcopilot.com/chat/completions"         â”‚
â”‚   //      or: "https://your-azure.openai.azure.com/..."                â”‚
â”‚                                                                          â”‚
â”‚   // 3. Format tools for API                                            â”‚
â”‚   const tools = options.tools?.map(tool => ({                           â”‚
â”‚     type: 'function',                                                    â”‚
â”‚     function: {                                                          â”‚
â”‚       name: tool.name,                                                   â”‚
â”‚       description: tool.description,                                    â”‚
â”‚       parameters: tool.inputSchema || {}                                â”‚
â”‚     }                                                                    â”‚
â”‚   }));                                                                   â”‚
â”‚                                                                          â”‚
â”‚   // 4. Make HTTP request to AI service                                 â”‚
â”‚   const response = await fetch(endpoint, {                              â”‚
â”‚     method: 'POST',                                                      â”‚
â”‚     headers: {                                                           â”‚
â”‚       'Authorization': `Bearer ${authToken}`,                           â”‚
â”‚       'Content-Type': 'application/json',                               â”‚
â”‚       'X-Request-Id': generateRequestId(),                              â”‚
â”‚       'Copilot-Integration-Id': 'vscode-chat'                           â”‚
â”‚     },                                                                   â”‚
â”‚     body: JSON.stringify({                                              â”‚
â”‚       model: 'claude-3-5-sonnet-20241022',  // Anthropic model ID      â”‚
â”‚       messages: messages.map(m => ({                                    â”‚
â”‚         role: m.role === 'user' ? 'user' : 'assistant',                 â”‚
â”‚         content: m.content                                              â”‚
â”‚       })),                                                               â”‚
â”‚       stream: true,                                                      â”‚
â”‚       tools: tools,                                                      â”‚
â”‚       tool_choice: options.toolMode === 'auto' ? 'auto' : undefined,   â”‚
â”‚       max_tokens: 4096,                                                  â”‚
â”‚       temperature: 0.7                                                   â”‚
â”‚     })                                                                   â”‚
â”‚   });                                                                    â”‚
â”‚                                                                          â”‚
â”‚   if (!response.ok) {                                                    â”‚
â”‚     throw new Error(`API error: ${response.status} ${response.statusText}`);â”‚
â”‚   }                                                                      â”‚
â”‚                                                                          â”‚
â”‚   // 5. Stream response via Server-Sent Events (SSE)                    â”‚
â”‚   const reader = response.body.getReader();                             â”‚
â”‚   const decoder = new TextDecoder();                                    â”‚
â”‚   let buffer = '';                                                       â”‚
â”‚                                                                          â”‚
â”‚   while (true) {                                                         â”‚
â”‚     if (token.isCancellationRequested) {                                â”‚
â”‚       reader.cancel();                                                  â”‚
â”‚       break;                                                            â”‚
â”‚     }                                                                    â”‚
â”‚                                                                          â”‚
â”‚     const { done, value } = await reader.read();                        â”‚
â”‚     if (done) break;                                                     â”‚
â”‚                                                                          â”‚
â”‚     buffer += decoder.decode(value, { stream: true });                  â”‚
â”‚     const lines = buffer.split('\n');                                   â”‚
â”‚     buffer = lines.pop() || '';                                         â”‚
â”‚                                                                          â”‚
â”‚     for (const line of lines) {                                         â”‚
â”‚       if (!line.startsWith('data: ')) continue;                         â”‚
â”‚       if (line === 'data: [DONE]') continue;                            â”‚
â”‚                                                                          â”‚
â”‚       const data = JSON.parse(line.slice(6));                           â”‚
â”‚       const delta = data.choices[0]?.delta;                             â”‚
â”‚                                                                          â”‚
â”‚       if (delta?.content) {                                             â”‚
â”‚         // Text content from model                                      â”‚
â”‚         progress.report(                                                â”‚
â”‚           new LanguageModelTextPart(delta.content)                      â”‚
â”‚         );                                                               â”‚
â”‚         // â–² This flows back through all layers to Chat UI             â”‚
â”‚                                                                          â”‚
â”‚       } else if (delta?.tool_calls) {                                   â”‚
â”‚         // Model is calling a tool                                      â”‚
â”‚         for (const toolCall of delta.tool_calls) {                      â”‚
â”‚           if (toolCall.function) {                                      â”‚
â”‚             progress.report(                                            â”‚
â”‚               new LanguageModelToolCallPart(                            â”‚
â”‚                 toolCall.id,                                            â”‚
â”‚                 toolCall.function.name,                                 â”‚
â”‚                 JSON.parse(toolCall.function.arguments)                 â”‚
â”‚               )                                                          â”‚
â”‚             );                                                           â”‚
â”‚             // â–² This triggers tool execution in the chat handler      â”‚
â”‚           }                                                              â”‚
â”‚         }                                                                â”‚
â”‚       }                                                                  â”‚
â”‚     }                                                                    â”‚
â”‚   }                                                                      â”‚
â”‚                                                                          â”‚
â”‚   // 6. Log telemetry                                                   â”‚
â”‚   this.telemetryService.logUsage('languageModel.request', {             â”‚
â”‚     model: 'claude-3-5-sonnet',                                         â”‚
â”‚     tokensUsed: response.headers.get('X-Token-Count'),                  â”‚
â”‚     duration: Date.now() - startTime                                    â”‚
â”‚   });                                                                    â”‚
â”‚ }                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ Progress reports flow back through all layers:
                      â”‚ ExtHostLanguageModels â†’ MainThreadLanguageModels
                      â”‚ â†’ LanguageModelsService â†’ ChatService â†’ ChatWidget
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chat UI Updates (Real-time)                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Each progress.report() call results in:                                 â”‚
â”‚                                                                          â”‚
â”‚ 1. Text Chunks: Rendered as markdown in chat message                    â”‚
â”‚    "I'll help you create a REST API for user management..."             â”‚
â”‚                                                                          â”‚
â”‚ 2. Tool Calls: Shown as "Using tool: create_file"                       â”‚
â”‚    progress indicator with tool name                                    â”‚
â”‚                                                                          â”‚
â”‚ 3. Tool Results: Displayed after tool execution                         â”‚
â”‚    "âœ“ Created file: src/api/users.ts"                                   â”‚
â”‚                                                                          â”‚
â”‚ 4. References: Shown as clickable links                                 â”‚
â”‚    "ğŸ“„ src/api/users.ts"                                                â”‚
â”‚                                                                          â”‚
â”‚ 5. Buttons: Interactive commands                                        â”‚
â”‚    [Open File] [Run Tests] [Deploy]                                     â”‚
â”‚                                                                          â”‚
â”‚ All updates appear immediately as streaming chunks arrive               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Timeline (approximate):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
0ms    â”‚ User presses Enter
10ms   â”‚ ChatWidget.acceptInput() called
15ms   â”‚ ChatService.sendRequest() - parsing complete
20ms   â”‚ Agent resolved (@copilot), context gathered
25ms   â”‚ IPC to Extension Host
30ms   â”‚ Extension handler starts
50ms   â”‚ Progress: "Analyzing your request..."  â—„â”€ First UI update
100ms  â”‚ model.sendRequest() called
150ms  â”‚ RPC to MainThreadLanguageModels
200ms  â”‚ LanguageModelAccess starts HTTP request
400ms  â”‚ First SSE chunk received from API
410ms  â”‚ First text appears in UI: "I'll help you..."  â—„â”€ Streaming starts
500ms  â”‚ Tool call detected: create_file
510ms  â”‚ UI shows: "Using tool: create_file"
600ms  â”‚ Tool executed, file created
610ms  â”‚ UI shows: "âœ“ Created file: src/api/users.ts"
800ms  â”‚ More text: "Here's the implementation..."
3000ms â”‚ Final text chunk received
3010ms â”‚ UI shows: [Open File] button
3020ms â”‚ Response complete, handler returns
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**Key Observations:**

1. **Streaming is Real-time**: Every `progress.report()` call immediately updates the UI
2. **Tool Execution is Automatic**: When model returns a tool call, it's automatically invoked
3. **Multi-turn with Tools**: After tool execution, results can be sent back to model for next iteration
4. **Cross-process Communication**: Data flows through multiple IPC/RPC boundaries efficiently
5. **Agent Model Capability**: Claude 3.5 Sonnet supports tool calling, enabling autonomous workflows

---

## Key Implementation Files

### VS Code Core
| File | Purpose |
|------|---------|
| `src/vs/workbench/contrib/chat/common/languageModels.ts` | LanguageModelsService - manages providers |
| `src/vs/workbench/contrib/chat/common/chatService.ts` | ChatService - orchestrates chat requests |
| `src/vs/workbench/api/browser/mainThreadLanguageModels.ts` | Main thread bridge for language models |
| `src/vs/workbench/api/browser/mainThreadChatAgents2.ts` | Main thread bridge for chat participants |
| `src/vs/workbench/contrib/chat/browser/chatWidget.ts` | Chat UI widget |
| `src/vscode-dts/vscode.proposed.chatProvider.d.ts` | Language Model Provider API types |
| `src/vscode-dts/vscode.proposed.chatParticipantAdditions.d.ts` | Chat Participant API types |

### GitHub Copilot Extension
| File | Purpose |
|------|---------|
| `src/extension/conversation/vscode-node/languageModelAccess.ts` | Language model provider implementation |
| `src/extension/conversation/conversation.contribution.ts` | Chat participant registration |
| `src/extension/conversation/copilotChatParticipant.ts` | @copilot participant |
| `src/extension/conversation/workspaceChatParticipant.ts` | @workspace participant |
| `src/extension/mcp/` | Model Context Protocol integration |

---

## Code Snippets from Real Implementation

### 1. Extension Activation (GitHub Copilot)

```typescript
// Simplified from vscode-copilot-chat/src/extension/extension/vscode/extension.ts
export async function activate(context: vscode.ExtensionContext) {
    // 1. Initialize authentication
    const authService = new AuthenticationService();
    
    // 2. Initialize language model provider
    const languageModelAccess = new LanguageModelAccess(
        authService,
        endpointService,
        telemetryService
    );
    
    // Register language models (gpt-4, claude, etc.)
    const models = [
        { id: 'gpt-4', name: 'GPT-4', vendor: 'copilot', family: 'gpt-4' },
        { id: 'gpt-4o', name: 'GPT-4o', vendor: 'copilot', family: 'gpt-4o' },
        { id: 'claude-3-5-sonnet', name: 'Claude 3.5 Sonnet', vendor: 'copilot', family: 'claude-3' },
        // ... more models
    ];
    
    context.subscriptions.push(
        languageModelAccess.registerLanguageModelProvider(models)
    );
    
    // 3. Register chat participants
    registerCopilotChatParticipant(context);
    registerWorkspaceChatParticipant(context);
    
    // 4. Register tools for agent mode
    registerChatTools(context);
}
```

### 2. Language Model API Usage (Extension consuming Copilot)

```typescript
// Any extension can use the language models provided by Copilot
async function askAI(prompt: string) {
    // 1. Select a model
    const [model] = await vscode.lm.selectChatModels({
        vendor: 'copilot',
        family: 'gpt-4o'
    });
    
    if (!model) {
        throw new Error('Model not available');
    }
    
    // 2. Build messages
    const messages = [
        vscode.LanguageModelChatMessage.User(prompt)
    ];
    
    // 3. Send request
    const response = await model.sendRequest(messages, {}, token);
    
    // 4. Collect response
    let result = '';
    for await (const fragment of response.text) {
        result += fragment;
    }
    
    return result;
}
```

### 3. Package.json Declaration (Chat Participant)

```json
{
  "contributes": {
    "chatParticipants": [
      {
        "id": "myext.assistant",
        "name": "assistant",
        "description": "AI assistant for your extension",
        "isSticky": true,
        "commands": [
          {
            "name": "explain",
            "description": "Explain the selected code"
          },
          {
            "name": "fix",
            "description": "Fix problems in the code"
          }
        ]
      }
    ]
  },
  "activationEvents": [
    "onChatParticipant:myext.assistant"
  ],
  "enabledApiProposals": [
    "chatProvider",
    "chatParticipantAdditions",
    "chatParticipantPrivate",
    "languageModels"
  ]
}
```

---

## Summary: How to Build a Copilot-like Extension

### Step 1: Implement Language Model Provider

```typescript
class MyLanguageModelProvider implements vscode.LanguageModelChatProvider {
    async provideLanguageModelChatResponse(
        model: vscode.LanguageModelChatInformation,
        messages: readonly vscode.LanguageModelChatRequestMessage[],
        options: vscode.ProvideLanguageModelChatResponseOptions,
        progress: vscode.Progress<vscode.LanguageModelResponsePart>,
        token: vscode.CancellationToken
    ): Promise<void> {
        // Call your AI service (OpenAI, Anthropic, local model, etc.)
        const response = await yourAIService.chat({
            model: model.id,
            messages: messages,
            stream: true
        });
        
        // Stream back to VS Code
        for await (const chunk of response) {
            progress.report(new vscode.LanguageModelTextPart(chunk.text));
        }
    }
}

// Register
vscode.lm.registerChatModelProvider('myext', new MyLanguageModelProvider(), models);
```

### Step 2: Create Chat Participants

```typescript
const participant = vscode.chat.createChatParticipant('myext.agent', async (request, context, stream, token) => {
    // Handle user request
    stream.progress('Thinking...');
    
    // Use language model
    const response = await request.model.sendRequest([
        vscode.LanguageModelChatMessage.User(request.prompt)
    ], {}, token);
    
    for await (const chunk of response.text) {
        stream.markdown(chunk);
    }
});
```

### Step 3: Add Agent Capabilities (Optional)

```typescript
// Register tools
vscode.lm.registerTool('myext_search', {
    name: 'search',
    description: 'Search workspace',
    invoke: async (options, token) => {
        const results = await performSearch(options.input);
        return new vscode.LanguageModelToolResult([
            new vscode.LanguageModelTextPart(JSON.stringify(results))
        ]);
    }
});

// Use tools in participant
const response = await request.model.sendRequest(messages, {
    tools: vscode.lm.tools,
    toolMode: vscode.LanguageModelChatToolMode.Auto
}, token);
```

---

